{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Presentación"]},{"cell_type":"markdown","metadata":{},"source":["Buenas, somos el grupo compuesto por David, Juan Cruz, Simón, Yessika y yo (Bruno) y para el trabajo nos dividimos en tres grupos (como los pinguinos). El primer grupo ... se encargó de todo lo relacionado con QDA. El segundo grupo ... se encargaron de todo lo relacionado con LDA y yo me encargué de la parte del ejercicio teórico."]},{"cell_type":"markdown","metadata":{"id":"ho-jvdLTQQLN"},"source":["## ***1.1 Punto 1***"]},{"cell_type":"markdown","metadata":{},"source":["Definimos una clase semi-genérica (try_prioris) para realizar las evaluaciones de los modelos,\n","en donde construimos una estructura de datos para guardar la información de todas las ejecuciones de los modelos. Realizamos para los cinco casos (sin a prioris, uniforme, clase0_90, clase1_90, clase2_90), guardamos los datos en la estructura y los mostramos en un dataframe."]},{"cell_type":"markdown","metadata":{},"source":["En el dataframe podemos ver para cada opción los datos de error tanto en el entrenamiento como en test. Las últimas columnas indican el error para dicha clase dentro del conjunto de test.\n","En este punto podemos ver que tanto con distribucioines uniformes y a priori (frecuencias relativas) brindan la misma presición."]},{"cell_type":"markdown","metadata":{"id":"UfvNzbEtRJlF"},"source":["También observamos que la distribución probabilística del dataset original es de 1/3 para cada clase. Por este motivo la probabilidad a priori uniforme otorga resultados consistentes con la probabiliad a priori calculada sobre el train set (aunque al splitearse de manera aleatoria puede variar su distribución, esta tiende a parecerse a una uniforme).\n","\n","Resulta interesante notar que la clase 2 (\"virginica\") es causante de los mayores errores de predicción, posiblemente por solapamiento con las otras clases en los features utilizados. Sin embargo, al seleccionar la priori en dónde la clase 2 posee probabilidad 0.9, el error en esa clase desaparece y se traslada a una de las otras clases.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"AEcbJHujR-BF"},"source":["## ***1.2 Punto 2***"]},{"cell_type":"markdown","metadata":{},"source":["En el punto 2, realizamos el mismo proceso que en el paso anterior utilizando la misma estructura de datos y obtuvimos el siguiente dataframe de datos."]},{"cell_type":"markdown","metadata":{"id":"Z9WZ9hySSJ-O"},"source":["En esta ocasión, dataset de los piguinos, observamos que utilizando las probabilidads a priori por defecto (relativas) el error global se debe principalmente a errores en la clasificación de la clase 0 ('adelie'). Al igual que en el punto anterior, al utilizar la probabilidad a priori que favorece la clase 0 otorgándole 90% de probabilidad, el error en la clase desaparece pero aparece en la clase 1. En este caso la distribución del dataset completo no es uniforme, por lo que el error de 0.016 que evitamos en la clase 0 equivale a un error de 0.042 en la clase 1."]},{"cell_type":"markdown","metadata":{"id":"Ftdu-eMUYmAY"},"source":["## ***1.5 Punto 5***"]},{"cell_type":"markdown","metadata":{"id":"4x34TvqQjggt"},"source":["Se disminuye a menos de la mitad la latencia del modelo. Esto se debe a que la tensorización del modelo nos permite calcular la probabilidad para las tres clases en una sola operación en el modelo TensorizedQDA, en lugar de secuencialmente como en el modelo QDA. Cabe destacar que esto se logra al tensorizar el ciclo que itera el número de clases en un dataset con sólo tres clases. En un dataset con mucha mayor cantidad de clases cabe esperar que esta mejora sea aún más significativa."]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
