{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\"><b> ETIQUETADO - PROYECTO FINAL </b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\">üìù <em><small><font color='Gray'>Nota:</font></small></em></div>\n",
    "\n",
    "<div align=\"right\"> <em><small><font color='Gray'> La funcionalidad de visualizaci√≥n de jupyter notebooks en <a href=\"https://github.com/\" target=\"_blank\">github</a> es solamente un preview.</font></small></em> </div>\n",
    "\n",
    "<div align=\"right\"> <em><small><font color='Gray'> Para mejor visualizaci√≥n se sugiere utilizar el visualizador recomendado por la comunidad: <a href=\"https://nbviewer.org/\" target=\"_blank\">nbviewer</a></font></small></em> </div>\n",
    "\n",
    "<div align=\"right\"> <em><small><font color='Gray'> Puedes a acceder al siguiente enlace para ver este notebook en dicha p√°gina: <a href=\"https://nbviewer.org/ruta/de/archivo.ipynb\">Ruta archivo</a></font></small></em> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "/* Limitar la altura de las celdas de salida en html */\n",
    ".jp-OutputArea.jp-Cell-outputArea {\n",
    "    max-height: 500px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úã <em><font color='DodgerBlue'>Importaciones:</font></em> ‚úã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, logging, json, shutil, zipfile, copy, datetime, re, requests\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Any, Optional, Literal\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../\"))  # Agregar el directorio padre al path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env.dev\")\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "from cvat_sdk import make_client\n",
    "from cvat_sdk.core.proxies.types import Location\n",
    "\n",
    "from pymongo import UpdateOne\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import layoutparser as lp\n",
    "\n",
    "OPENCV_IO_MAX_IMAGE_PIXELS = 50000 * 50000  # Para im√°genes grandes, ej: barrio3Ombues_20180801_dji_pc_3cm.jpg\n",
    "os.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = str(OPENCV_IO_MAX_IMAGE_PIXELS)\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "from fastkml import kml\n",
    "import kml2geojson\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, box\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from apps_config.settings import Config\n",
    "from apps_com_db.mongodb_client import MongoDB\n",
    "from apps_com_s3.minio_client import S3Client\n",
    "from apps_utils.logging import Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîß <em><font color='tomato'>Configuraciones:</font></em> üîß\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-17 17:22:17,378 - root - INFO - <module> - Configuraci√≥n cargada correctamente.\n"
     ]
    }
   ],
   "source": [
    "CONFIG = Config().config_data\n",
    "DB = MongoDB().db\n",
    "MINIO_CLIENT = S3Client().client\n",
    "LOGGER = Logging().logger\n",
    "\n",
    "MINIO_BUCKET = CONFIG[\"minio\"][\"bucket\"]\n",
    "\n",
    "MINIO_PATCHES_FOLDER = CONFIG[\"minio\"][\"paths\"][\"patches\"]\n",
    "download_folder = Path(CONFIG[\"folders\"][\"download_folder\"])\n",
    "DOWNLOAD_TASK_FOLDER = download_folder / \"tasks\"\n",
    "DOWNLOAD_JOB_FOLDER = download_folder / \"jobs\"\n",
    "DOWNLOAD_TEMP_FOLDER = download_folder / \"temp\"\n",
    "DOWNLOAD_COCO_ANNOTATIONS_FOLDER = download_folder / \"coco_annotations\"\n",
    "DOWNLOAD_IMAGES_FOLDER = download_folder / \"images\"\n",
    "DOWNLOAD_PATCHES_FOLDER = download_folder / \"patches\"\n",
    "DOWNLOAD_CUTOUTS_FOLDER = download_folder / \"cutouts\"\n",
    "DOWNLOAD_CUTOUTS_METADATA_FOLDER = download_folder / \"cutouts_metadata\"\n",
    "DOWNLOAD_GOOGLE_MAPS_FOLDER = download_folder / \"google_maps\"\n",
    "KMLS_FOLDER = download_folder / \"kmls\"\n",
    "GEOJSON_FOLDER = download_folder / \"geojson\"\n",
    "\n",
    "LOGGER.info(\"Configuraci√≥n cargada correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Colab -->\n",
    "<!-- <div align=\"center\"><img src=\"https://drive.google.com/uc?export=view&id=1QSNrTsz1hQbmZwpgwx0qpfpNtLW19Orm\" width=\"600\" alt=\"Figura 1: A data scientist is working on word generation using the Lord of the Rings lore. The image is dark and moody, with a focus on the scientist's computer screen. The screen displays a visualization the one ring, with a map of Middle Earth in the background. - Generada con DALL-E3\"></div> -->\n",
    "\n",
    "<!-- <div align=\"center\"><img src=\"./ceia-materia/resources/portada.jpeg\" width=\"600\" alt=\"Figura 1: A data scientist playing with convolutional neural networks. - Generada con Microsoft Image Creator\"></div>\n",
    "\n",
    "<div align=\"center\"><small><em>Figura 1: A data scientist playing with convolutional neural networks. - Generada con Microsoft Image Creator</em></small></div> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">‚ú®Datos del proyecto:‚ú®</div>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "| Subtitulo       | Etiquetado                                                                                                                             |\n",
    "| --------------- | -------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Descrpci√≥n**  | Herramientas y scripts para el etiquetado y guardado de los datos                                                                      |\n",
    "| **Integrantes** | Bruno Masoller (brunomaso1@gmail.com)                                                                                                  |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consinga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este proyecto es brindar herramientas y scripts para el etiquetado y guardado de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resoluci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilidades de Ultralytics:\n",
    "\n",
    "- [https://docs.ultralytics.com/es/usage/simple-utilities/](https://docs.ultralytics.com/es/usage/simple-utilities/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anotaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para las anotaciones, entre varios formatos estudiados, se eligi√≥ el formato de COCO.\n",
    "\n",
    "- [https://roboflow.com/formats/coco-json](https://roboflow.com/formats/coco-json)\n",
    "- [https://docs.voxel51.com/recipes/convert_datasets.html](https://docs.voxel51.com/recipes/convert_datasets.html)\n",
    "- [https://stackoverflow.com/questions/75927857/how-to-convert-coco-json-to-yolov8-segmentation-format](https://stackoverflow.com/questions/75927857/how-to-convert-coco-json-to-yolov8-segmentation-format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interacci√≥n con google maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generaci√≥n de mapa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procesamiento de archivos KML:\n",
    "- `fastkml` $\\rightarrow$ [https://fastkml.readthedocs.io/en/latest/quickstart.html](https://fastkml.readthedocs.io/en/latest/quickstart.html)\n",
    "\n",
    "Conversi√≥n de archivos KML a GeoJSON:\n",
    "- `kml2geojson` $\\rightarrow$ [https://pypi.org/project/kml2geojson/](https://pypi.org/project/kml2geojson/) | [https://github.com/mrcagney/kml2geojson](https://github.com/mrcagney/kml2geojson)\n",
    "\n",
    "Visualizaci√≥n:\n",
    "- `folium` $\\rightarrow$ [https://python-visualization.github.io/folium/latest/](https://python-visualization.github.io/folium/latest/)\n",
    "- `geojson.io` $\\rightarrow$ [https://geojson.io/#map=2/0/20](https://geojson.io/#map=2/0/20)\n",
    "\n",
    "Trabajo con archivos GeoJSON:\n",
    "- `geojson` $\\rightarrow$ [https://github.com/jazzband/geojson](https://github.com/jazzband/geojson) | [https://geojson.org/](https://geojson.org/)\n",
    "- `geopandas` $\\rightarrow$ [https://geopandas.org/](https://geopandas.org/)\n",
    "- `shapely` $\\rightarrow$ [https://shapely.readthedocs.io/en/latest/manual.html](https://shapely.readthedocs.io/en/latest/manual.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_kmz_from_gmaps(\n",
    "    base_url: str = CONFIG[\"google_maps\"][\"base_url\"],\n",
    "    mid: str = CONFIG[\"google_maps\"][\"mid\"],\n",
    "    output_filename: Optional[Path] = None,\n",
    ") -> Optional[Path]:\n",
    "    \"\"\"Descarga un archivo KMZ desde Google Maps y lo descomprime.\n",
    "\n",
    "    Este m√©todo utiliza la configuraci√≥n proporcionada para construir la URL de descarga\n",
    "    del archivo KMZ desde Google Maps. Una vez descargado, el archivo se descomprime\n",
    "    y se guarda en la carpeta especificada.\n",
    "\n",
    "    Args:\n",
    "        filename (str, optional): Ruta donde se guardar√° el archivo KMZ descargado.\n",
    "                                  Si no se proporciona, se utiliza una ruta temporal.\n",
    "\n",
    "    Returns:\n",
    "        str: Ruta del archivo KML descargado y descomprimido.\n",
    "\n",
    "    Raises:\n",
    "        Exception: Si ocurre un error al acceder a la URL de descarga.\n",
    "    \"\"\"\n",
    "    url = f\"{base_url}?mid={mid}\"\n",
    "    if not output_filename:\n",
    "        Path(DOWNLOAD_TEMP_FOLDER).mkdir(parents=True, exist_ok=True)\n",
    "        output_filename = DOWNLOAD_TEMP_FOLDER / \"google_maps.kmz\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        with open(output_filename, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        LOGGER.debug(f\"Archivo KMZ descargado y guardado en {output_filename}.\")\n",
    "\n",
    "        extract_path = (\n",
    "            DOWNLOAD_GOOGLE_MAPS_FOLDER / f\"google_maps_{mid}_{datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")}.kmz\"\n",
    "        )\n",
    "\n",
    "        # Descomprimir el archivo KMZ\n",
    "        with zipfile.ZipFile(output_filename, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "        LOGGER.debug(f\"Archivo KMZ descomprimido en {extract_path}.\")\n",
    "\n",
    "        # Clear the temporary file\n",
    "        os.remove(output_filename)\n",
    "\n",
    "        return f\"{extract_path}/doc.kml\"\n",
    "\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        raise Exception(f\"Error al acceder a {url}. Raz√≥n: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_kml_to_geojson(kml_file_path: Path, geojson_file_path: Optional[Path]) -> Optional[Path]:\n",
    "    \"\"\"\n",
    "    Convierte un archivo KML a formato GeoJSON.\n",
    "\n",
    "    Args:\n",
    "        kml_file_path (str): Ruta al archivo KML de entrada.\n",
    "        geojson_file_path (str): Ruta donde se guardar√° el archivo GeoJSON convertido.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        geojson = kml2geojson.main.convert(kml_file_path)[0]\n",
    "        LOGGER.info(f\"Conversi√≥n exitosa de '{kml_file_path}' a '{geojson_file_path}'.\")\n",
    "\n",
    "        if not geojson_file_path:\n",
    "            Path(DOWNLOAD_GOOGLE_MAPS_FOLDER).mkdir(parents=True, exist_ok=True)\n",
    "            geojson_file_path = DOWNLOAD_GOOGLE_MAPS_FOLDER / f\"{kml_file_path.stem}.geojson\"\n",
    "        # Guardar el archivo GeoJSON\n",
    "        with open(geojson_file_path, \"w\") as f:\n",
    "            json.dump(geojson, f, indent=4)\n",
    "            return geojson_file_path\n",
    "        LOGGER.info(f\"Archivo GeoJSON guardado en '{geojson_file_path}'.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        LOGGER.error(f\"Error: Archivo KML no encontrado en '{kml_file_path}'.\")\n",
    "    except ValueError as e:\n",
    "        LOGGER.error(f\"Error de valor: {e}\")\n",
    "    except Exception as e:\n",
    "        LOGGER.error(f\"Ocurri√≥ un error inesperado: {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_geojson_from_annotation(\n",
    "    pic_name: str,\n",
    "    coco_annotation: Dict[str, Any],\n",
    "    jgw_data: Dict[str, Any],\n",
    "    output_filename: Optional[Path] = None,\n",
    "    upload_to_drive: bool = False,\n",
    "    geo_sistema_referencia: str = CONFIG[\"georeferenciacion\"][\"codigo_epsg\"],\n",
    ") -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Crea un GeoDataFrame a partir de las anotaciones COCO y datos de georreferenciaci√≥n.\n",
    "\n",
    "    Args:\n",
    "        pic_name (str): Nombre de la imagen para la cual se generar√° el GeoJSON.\n",
    "        coco_annotation (Dict[str, Any]): Anotaciones en formato COCO que incluyen categor√≠as y bounding boxes.\n",
    "        jgw_data (Dict[str, Any]): Datos de georreferenciaci√≥n provenientes de un archivo JGW.\n",
    "        output_filename (Optional[Path], optional): Ruta donde se guardar√° el archivo GeoJSON. Defaults to None.\n",
    "        upload_to_drive (bool, optional): Indica si el archivo GeoJSON debe subirse a Google Drive. Defaults to False.\n",
    "        geo_sistema_referencia (str, optional): C√≥digo EPSG del sistema de referencia geogr√°fico. Defaults to CONFIG[\"georeferenciacion\"][\"codigo_epsg\"].\n",
    "\n",
    "    Raises:\n",
    "        NotImplementedError: Si se solicita subir el archivo a Google Drive, pero la funcionalidad no est√° implementada.\n",
    "\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: GeoDataFrame que contiene las geometr√≠as y propiedades de las anotaciones.\n",
    "\n",
    "    Ejemplo de uso:\n",
    "\n",
    "        >>> image_name = \"8deOctubreyCentenario-EspLibreLarranaga_20190828_dji_pc_5cm\"\n",
    "        >>> patch_name = \"8deOctubreyCentenario-EspLibreLarranaga_20190828_dji_pc_5cm_patch_0\"\n",
    "        >>> annotations_field = \"cvat\"\n",
    "        >>> pic_name = image_name\n",
    "        >>> if pic_name == image_name:\n",
    "        >>>     coco_annotations = load_coco_annotation_from_mongodb(\n",
    "        ...         field_name=annotations_field, image_name=image_name\n",
    "        ...     )\n",
    "        >>>     jgw_data = load_jgw_file_from_mongodb(image_name=image_name)\n",
    "        >>> else:\n",
    "        >>>     coco_annotations = load_coco_annotation_from_mongodb(\n",
    "        ...         field_name=annotations_field, patch_name=patch_name\n",
    "        ...     )\n",
    "        >>>     jgw_data = load_jgw_file_from_mongodb(patch_name=patch_name)\n",
    "        >>> gdf = create_geojson_from_annotation(\n",
    "        ...     pic_name=pic_name,\n",
    "        ...     coco_annotation=coco_annotations,\n",
    "        ...     jgw_data=jgw_data,\n",
    "        ...     output_filename=DOWNLOAD_TEMP_FOLDER / f\"{pic_name}.geojson\",\n",
    "        ... )\n",
    "\n",
    "        >>> # Cambiar proyectar en otro sistema de coordenadas\n",
    "        >>> # gdf_crs = gdf.to_crs(\"EPSG:4326\")\n",
    "        >>> # gdf_crs.to_file(\n",
    "        ... #     DOWNLOAD_TEMP_FOLDER / f\"{pic_name}_4326.geojson\",\n",
    "        ... #     driver=\"GeoJSON\",\n",
    "        ... # )\n",
    "    \"\"\"\n",
    "    # 1 - Configuraciones generales\n",
    "    category_map = {cat[\"id\"]: cat[\"name\"] for cat in coco_annotation[\"categories\"]}\n",
    "\n",
    "    # 2 - Obtener el id de la imagen en las anotaciones\n",
    "    image_id = get_image_id_from_annotations(pic_name, coco_annotation)\n",
    "\n",
    "    # 3 - Obtener las anotaciones de la imagen\n",
    "    annotations = [ann for ann in coco_annotation[\"annotations\"] if ann[\"image_id\"] == image_id]\n",
    "    if not annotations:\n",
    "        LOGGER.warning(f\"No se encontraron anotaciones para la imagen {pic_name}.\")\n",
    "        return gpd.GeoDataFrame()\n",
    "\n",
    "    # 4 - Preparar listas para almacenar los datos\n",
    "    geometries = []\n",
    "    properties = []\n",
    "\n",
    "    # 5 - Para cada anotaci√≥n, obtener el bbox y la categor√≠a\n",
    "    for annotation in annotations:\n",
    "        bbox = annotation[\"bbox\"]\n",
    "        category_name = category_map.get(annotation[\"category_id\"], \"Sin categor√≠a\")\n",
    "\n",
    "        # 5.1 - Convertir el bbox a coordenadas geogr√°ficas utilizando los datos del archivo JGW\n",
    "        global_coordinates = convert_bbox_image_to_world(bbox, jgw_data)\n",
    "\n",
    "        # 5.2 - Obtener el centroide del bbox\n",
    "        x_coords = [\n",
    "            global_coordinates[\"tl\"][0],\n",
    "            global_coordinates[\"tr\"][0],\n",
    "            global_coordinates[\"br\"][0],\n",
    "            global_coordinates[\"bl\"][0],\n",
    "        ]\n",
    "        y_coords = [\n",
    "            global_coordinates[\"tl\"][1],\n",
    "            global_coordinates[\"tr\"][1],\n",
    "            global_coordinates[\"br\"][1],\n",
    "            global_coordinates[\"bl\"][1],\n",
    "        ]\n",
    "        centroid_x = sum(x_coords) / len(x_coords)\n",
    "        centroid_y = sum(y_coords) / len(y_coords)\n",
    "        centroid = (centroid_x, centroid_y)\n",
    "\n",
    "        # 5.3 - Crear un objeto Point de Shapely con las coordenadas del centroide\n",
    "        point = Point(centroid)\n",
    "\n",
    "        # 5.4 - Guardar la geometr√≠a y propiedades\n",
    "        geometries.append(point)\n",
    "        properties.append(\n",
    "            {\n",
    "                \"category\": category_name,\n",
    "                \"annotation_id\": annotation.get(\"id\", None),\n",
    "                \"bbox_x\": bbox[0],\n",
    "                \"bbox_y\": bbox[1],\n",
    "                \"bbox_width\": bbox[2],\n",
    "                \"bbox_height\": bbox[3],\n",
    "                \"global_tl_x\": global_coordinates[\"tl\"][0],\n",
    "                \"global_tl_y\": global_coordinates[\"tl\"][1],\n",
    "                \"global_br_x\": global_coordinates[\"br\"][0],\n",
    "                \"global_br_y\": global_coordinates[\"br\"][1],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # 6 - Crear un DataFrame con las propiedades\n",
    "    properties_df = pd.DataFrame(properties)\n",
    "\n",
    "    # 7 - Crear un GeoDataFrame con las geometr√≠as y propiedades\n",
    "    gdf = gpd.GeoDataFrame(properties_df, geometry=geometries)\n",
    "\n",
    "    # 8 - Configurar el sistema de coordenadas (CRS)\n",
    "    gdf.crs = geo_sistema_referencia\n",
    "\n",
    "    # 9 - Guardar como GeoJSON si se proporciona un nombre de archivo\n",
    "    if output_filename:\n",
    "        output_path = output_filename\n",
    "        Path(output_path.parent).mkdir(parents=True, exist_ok=True)\n",
    "        gdf.to_file(output_path, driver=\"GeoJSON\")\n",
    "        LOGGER.info(f\"GeoJSON guardado en {output_path}\")\n",
    "\n",
    "        # 10 - Opcional: Subir a Google Drive si se solicita\n",
    "        if upload_to_drive:\n",
    "            # Aqu√≠ ir√≠a tu c√≥digo para subir a Drive\n",
    "            raise NotImplementedError(\"Subida a Google Drive no implementada.\")\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se est√° generando el archivo con unos tags incorrectos.\n",
    "def create_kml_from_geojson(\n",
    "    gdf: gpd.GeoDataFrame,\n",
    "    kml_filename: Optional[Path] = None,\n",
    "    category_column: str = \"category\",\n",
    "    target_category: Optional[str] = \"palmera\",\n",
    "    reproject: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Crea un archivo KML a partir de un GeoDataFrame.\n",
    "\n",
    "    Este m√©todo toma un GeoDataFrame con geometr√≠as y propiedades, filtra las categor√≠as\n",
    "    deseadas, y genera un archivo KML con las geometr√≠as y propiedades correspondientes.\n",
    "\n",
    "    Args:\n",
    "        gdf (gpd.GeoDataFrame): GeoDataFrame que contiene las geometr√≠as y propiedades.\n",
    "        kml_filename (Optional[Path], optional): Ruta donde se guardar√° el archivo KML.\n",
    "                                                 Si no se proporciona, se utiliza una ruta predeterminada.\n",
    "                                                 Defaults to None.\n",
    "        category_column (str, optional): Nombre de la columna que contiene las categor√≠as.\n",
    "                                         Defaults to \"category\".\n",
    "        target_category (Optional[str], optional): Categor√≠a objetivo que se desea incluir en el KML.\n",
    "                                                   Si no se proporciona, se incluyen todas las categor√≠as.\n",
    "                                                   Defaults to \"palmera\".\n",
    "        reproject (bool, optional): Si se debe reproyectar el GeoDataFrame a EPSG:4326 (WGS84).\n",
    "                                    Defaults to True.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Si ocurre un error al reproyectar el GeoDataFrame.\n",
    "\n",
    "    Returns:\n",
    "        None: El archivo KML se guarda en la ubicaci√≥n especificada o predeterminada.\n",
    "\n",
    "    Ejemplo de uso:\n",
    "\n",
    "        >>> image_name = \"8deOctubreyCentenario-EspLibreLarranaga_20190828_dji_pc_5cm\"\n",
    "        >>> patch_name = \"8deOctubreyCentenario-EspLibreLarranaga_20190828_dji_pc_5cm_patch_0\"\n",
    "        >>> annotations_field = \"cvat\"\n",
    "        >>> pic_name = image_name\n",
    "        >>> if pic_name == image_name:\n",
    "        >>>     coco_annotations = load_coco_annotation_from_mongodb(\n",
    "        ...         field_name=annotations_field, image_name=image_name\n",
    "        ...     )\n",
    "        >>>     jgw_data = load_jgw_file_from_mongodb(image_name=image_name)\n",
    "        >>> else:\n",
    "        >>>     coco_annotations = load_coco_annotation_from_mongodb(\n",
    "        ...         field_name=annotations_field, patch_name=patch_name\n",
    "        ...     )\n",
    "        >>>     jgw_data = load_jgw_file_from_mongodb(patch_name=patch_name)\n",
    "        >>> gdf = create_geojson_from_annotation(\n",
    "        ...     pic_name=pic_name,\n",
    "        ...     coco_annotation=coco_annotations,\n",
    "        ...     jgw_data=jgw_data,\n",
    "        ...     output_filename=DOWNLOAD_TEMP_FOLDER / f\"{pic_name}.geojson\",\n",
    "        ... )\n",
    "        >>> create_kml_from_geojson(\n",
    "        ...     gdf=gdf,\n",
    "        ...     kml_filename=KMLS_FOLDER / f\"{pic_name}.kml\",\n",
    "        ...     category_column=\"category\",\n",
    "        ...     target_category=None\n",
    "        ... )\n",
    "    \"\"\"\n",
    "    k = kml.KML()\n",
    "    ns = \"{http://www.opengis.net/kml/2.2}\"\n",
    "\n",
    "    # Crear un documento KML\n",
    "    palm_document = kml.Document(ns, id=\"docid\", description=\"PalmTrees\")\n",
    "    k.append(palm_document)\n",
    "\n",
    "    # Crear una carpeta para las palmeras\n",
    "    palm_folder = kml.Folder(ns, id=\"palmeras_folder\", name=\"Palmeras\")\n",
    "    palm_document.append(palm_folder)\n",
    "\n",
    "    if target_category:\n",
    "        palm_gdf = gdf[gdf[category_column] == target_category].copy()\n",
    "    else:\n",
    "        palm_gdf = gdf.copy()\n",
    "\n",
    "    if palm_gdf.empty:\n",
    "        LOGGER.warning(\n",
    "            f\"No se encontraron elementos con la categor√≠a '{target_category}'. No se crear√° el archivo KML.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    # Reproyectar a WGS84 (EPSG:4326) si no est√° ya en ese CRS\n",
    "    if reproject and palm_gdf.crs is not None and palm_gdf.crs != \"EPSG:4326\":\n",
    "        try:\n",
    "            palm_gdf = palm_gdf.to_crs(epsg=4326)\n",
    "            LOGGER.debug(\"GeoDataFrame reproyectado a EPSG:4326 para el KML.\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(\n",
    "                f\"Error al reproyectar el GeoDataFrame a EPSG:4326: {e}. Aseg√∫rate de que el CRS original sea v√°lido.\"\n",
    "            )\n",
    "\n",
    "    for index, row in palm_gdf.iterrows():\n",
    "        if row.geometry.geom_type == \"Point\":\n",
    "            coords = (row.geometry.x, row.geometry.y)\n",
    "            point = Point(coords)\n",
    "            p = kml.Placemark(ns, id=f\"palmera_{index}\", name=f\"{row.category}\", geometry=point)\n",
    "            palm_folder.append(p)\n",
    "        else:\n",
    "            LOGGER.warning(f\"La geometr√≠a del elemento con √≠ndice {index} no es un Point. No se agregar√° al KML.\")\n",
    "\n",
    "    if kml_filename:\n",
    "        Path(kml_filename).parent.mkdir(parents=True, exist_ok=True)\n",
    "    else:\n",
    "        Path(KMLS_FOLDER).mkdir(parents=True, exist_ok=True)\n",
    "        kml_filename = KMLS_FOLDER / f\"kml_{target_category}_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}.kml\"\n",
    "    try:\n",
    "        k.write(kml_filename)\n",
    "        LOGGER.info(f\"Archivo KML guardado en {kml_filename}\")\n",
    "    except Exception as e:\n",
    "        LOGGER.error(f\"Error al guardar el archivo KML: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gdf_from_file(\n",
    "    file_path: Path,\n",
    "    crs: Optional[str] = None,\n",
    ") -> gpd.GeoDataFrame:\n",
    "    \"\"\"Carga un archivo GeoJSON y lo convierte a un GeoDataFrame.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Ruta al archivo GeoJSON.\n",
    "        driver (str, optional): Controla el formato del archivo. Defaults to \"GeoJSON\".\n",
    "        crs (str, optional): Sistema de referencia de coordenadas. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: GeoDataFrame que contiene los datos del archivo.\n",
    "    \"\"\"\n",
    "    gdf = gpd.read_file(file_path)\n",
    "    if crs:\n",
    "        gdf.crs = crs\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procesamiento de mapas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_patch(\n",
    "    imagen: Dict[str, Any],\n",
    "    patch: Dict[str, Any],\n",
    "    gdf: gpd.GeoDataFrame,\n",
    "    bbox_size: Tuple[float, float] = (CONFIG[\"bbox_size\"][\"width\"], CONFIG[\"bbox_size\"][\"height\"]),\n",
    ") -> Tuple[Dict[str, Any], List[Dict[str, Any]]]:\n",
    "    image = {\n",
    "        \"width\": patch[\"width\"],\n",
    "        \"height\": patch[\"height\"],\n",
    "        \"file_name\": f\"{patch[\"patch_name\"]}.jpg\",\n",
    "        \"date_captured\": imagen[\"date_captured\"].strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    }\n",
    "    annotations = []\n",
    "    jgw_data = imagen.get(\"jgw_data\")\n",
    "    if not jgw_data:\n",
    "        LOGGER.warning(f\"No se encontr√≥ el archivo JGW para la imagen {imagen['name']}.\")\n",
    "        return image, annotations\n",
    "\n",
    "    # Obtener las coordenadas del parche\n",
    "    x_start, y_start, patch_width, patch_height = (\n",
    "        patch[\"x_start\"],\n",
    "        patch[\"y_start\"],\n",
    "        patch[\"width\"],\n",
    "        patch[\"height\"],\n",
    "    )\n",
    "    # Esquinas del parche dentro de la imagen\n",
    "    esquinas_imagen = [\n",
    "        (x_start, y_start),  # esquina superior izquierda\n",
    "        (x_start + patch_width, y_start),  # esquina superior derecha\n",
    "        (x_start + patch_width, y_start + patch_height),  # esquina inferior derecha\n",
    "        (x_start, y_start + patch_height),  # esquina inferior izquierda\n",
    "    ]\n",
    "\n",
    "    # Convertir las coordenadas del parche a coordenadas globales\n",
    "    esquinas_mundo = [convert_point_image_to_world(punto, jgw_data=jgw_data) for punto in esquinas_imagen]\n",
    "\n",
    "    poligono_parche = Polygon(esquinas_mundo)\n",
    "\n",
    "    # Filtrar los puntos del GeoDataFrame que est√°n dentro del pol√≠gono del parche\n",
    "    puntos_en_parche = gdf[gdf.geometry.within(poligono_parche)]\n",
    "\n",
    "    if puntos_en_parche.empty:\n",
    "        LOGGER.debug(f\"No se encontraron puntos dentro del parche {patch['patch_name']}.\")\n",
    "        return image, annotations\n",
    "\n",
    "    # Procesar cada punto encontrado del parche\n",
    "    puntos_en_parche.reset_index(inplace=True, drop=True)\n",
    "    for index, row in puntos_en_parche.iterrows():\n",
    "        punto_mundo = (row.geometry.x, row.geometry.y)\n",
    "\n",
    "        # Convertir a coordenadas de imagen\n",
    "        punto_imagen = convert_point_world_to_image(punto_mundo, jgw_data)\n",
    "\n",
    "        # Convertir a coordenadas locales del parche\n",
    "        punto_parche = convert_point_image_to_patch(punto_imagen, x_start, y_start, patch_width, patch_height)\n",
    "\n",
    "        # Crear el bounding box\n",
    "        bbox_ancho, bbox_alto = bbox_size\n",
    "        x_centro, y_centro = punto_parche\n",
    "\n",
    "        # Asegurarse que el bbox no exceda los l√≠mites del parche\n",
    "        x_min = max(0, x_centro - bbox_ancho / 2)\n",
    "        y_min = max(0, y_centro - bbox_alto / 2)\n",
    "        x_max = min(patch_width, x_centro + bbox_ancho / 2)\n",
    "        y_max = min(patch_height, y_centro + bbox_alto / 2)\n",
    "\n",
    "        # Calcular dimensiones finales del bbox\n",
    "        ancho = x_max - x_min\n",
    "        alto = y_max - y_min\n",
    "        area = ancho * alto\n",
    "\n",
    "        category_name = \"palmera-google-maps\"\n",
    "        annotation = {\n",
    "            \"id\": index + 1,\n",
    "            \"segmentation\": [],\n",
    "            \"iscrowd\": 0,\n",
    "            \"attributes\": {\n",
    "                \"occluded\": False,\n",
    "                \"rotation\": 0.0,\n",
    "            },\n",
    "            \"category_name\": category_name,\n",
    "            \"area\": area,\n",
    "            \"bbox\": [x_min, y_min, ancho, alto],\n",
    "        }\n",
    "\n",
    "        annotations.append(annotation)\n",
    "\n",
    "    return image, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_annotations_from_geojson(\n",
    "    gdf: gpd.GeoDataFrame,\n",
    "    output_filename: Optional[Path] = None,\n",
    "    use_parallel: bool = True,\n",
    "    max_workers: int = 10,\n",
    ") -> Dict[str, Any]:\n",
    "    coco_annotations = {\n",
    "        \"info\": CONFIG[\"coco_dataset\"][\"info\"],\n",
    "        \"licenses\": CONFIG[\"coco_dataset\"][\"licenses\"],\n",
    "        \"categories\": CONFIG[\"google_maps\"][\"categories\"],\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "    }\n",
    "\n",
    "    category_map = {cat[\"name\"]: cat[\"id\"] for cat in coco_annotations[\"categories\"]}\n",
    "\n",
    "    coco_images = []\n",
    "    image_annotations = []\n",
    "    imagenes = DB.get_collection(\"imagenes\")\n",
    "\n",
    "    # Consulta con agregaci√≥n para filtrar im√°genes y sus patches\n",
    "    pipeline = [\n",
    "        # Filtrar im√°genes donde downloaded = true\n",
    "        {\"$match\": {\"downloaded\": True}},\n",
    "        # Crear un nuevo campo 'patches_filtrados' que contenga solo los patches donde is_white = false\n",
    "        {\n",
    "            \"$addFields\": {\n",
    "                \"patches_filtrados\": {\n",
    "                    \"$filter\": {\"input\": \"$patches\", \"as\": \"patch\", \"cond\": {\"$eq\": [\"$$patch.is_white\", False]}}\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        # Filtrar para incluir solo im√°genes que tienen al menos un patch v√°lido\n",
    "        {\"$match\": {\"patches_filtrados.0\": {\"$exists\": True}}},\n",
    "        # Opcionalmente: proyectar solo campos necesarios con $project (mejorar optimizaci√≥n, pero queda hardcodeado)\n",
    "    ]\n",
    "\n",
    "    filtered_images = list(imagenes.aggregate(pipeline))\n",
    "    LOGGER.debug(f\"Se encontraron {len(filtered_images)} im√°genes con parches no blancos.\")\n",
    "\n",
    "    # Creamos tareas as√≠ncronas para cada imagen y parche\n",
    "    tareas = [(imagen, patch) for imagen in filtered_images for patch in imagen[\"patches_filtrados\"]]\n",
    "    LOGGER.debug(f\"Se encontraron {len(tareas)} tareas para procesar.\")\n",
    "\n",
    "    if tareas:\n",
    "        annotation_images = []\n",
    "        if use_parallel:\n",
    "            with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "                futures = [(executor.submit(process_single_patch, imagen, patch, gdf)) for imagen, patch in tareas]\n",
    "                for future in tqdm(futures, desc=\"Procesando parches\"):\n",
    "                    try:\n",
    "                        image, annotations = future.result()\n",
    "                        if image and annotations:\n",
    "                            annotation_images.append((image, annotations))\n",
    "                    except Exception as e:\n",
    "                        LOGGER.error(f\"Error procesando el parche: {e}\")\n",
    "        else:\n",
    "            for imagen, patch in tqdm(tareas, desc=\"Procesando parches\"):\n",
    "                try:\n",
    "                    image, annotations = process_single_patch(imagen, patch, gdf)\n",
    "                    if image and annotations:\n",
    "                        annotation_images.append((image, annotations))\n",
    "                except Exception as e:\n",
    "                    LOGGER.error(f\"Error procesando el parche: {e}\")\n",
    "\n",
    "        for id, image, annotations in enumerate(annotation_images):\n",
    "            image_id = id + 1\n",
    "            image = {\"id\": image_id, **image}\n",
    "\n",
    "            annotations = [\n",
    "                {\n",
    "                    **annotation,\n",
    "                    \"image_id\": image_id,\n",
    "                    \"category_id\": category_map[annotation[\"category_name\"]],\n",
    "                }\n",
    "                for annotation in annotations\n",
    "            ]\n",
    "\n",
    "            coco_images.append(image)\n",
    "            image_annotations.append(annotations)\n",
    "\n",
    "        coco_annotations[\"images\"] = coco_images\n",
    "        coco_annotations[\"annotations\"] = image_annotations\n",
    "\n",
    "        if output_filename:\n",
    "            with open(output_filename, \"w\") as f:\n",
    "                json.dump(coco_annotations, f, indent=4)\n",
    "                LOGGER.debug(f\"Anotaciones guardadas en {output_filename}\")\n",
    "\n",
    "        pprint(coco_annotations)\n",
    "    else:\n",
    "        LOGGER.warning(\"No se encontraron tareas para procesar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf = load_gdf_from_file(DOWNLOAD_TEMP_FOLDER / \"google_maps.geojson\", crs=CONFIG[\"georeferenciacion\"][\"codigo_epsg\"])\n",
    "# output_filename = None\n",
    "# use_parallel = False\n",
    "# max_workers = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_annotations():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de carga de anotaciones\n",
    "\n",
    "- Desde CVAT:\n",
    "```python\n",
    "coco_annotations = load_annotations_from_cvat(task_id=8)\n",
    "save_coco_annotations(coco_annotations=coco_annotations, field_name=\"cvat\")\n",
    "```\n",
    "\n",
    "- Desde un archivo:\n",
    "```python\n",
    "coco_annotations = load_annotations_from_file(file_path=\"cvat.json\")\n",
    "save_coco_annotations(coco_annotations=coco_annotations, field_name=\"cvat\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patches_list = [\n",
    "#     \"8deOctubreyCentenario-EspLibreLarranaga_20190828_dji_pc_5cm_patch_0\",\n",
    "#     \"8deOctubreyCentenario-EspLibreLarranaga_20190828_dji_pc_5cm_patch_2\",\n",
    "# ]\n",
    "# images_list = [\"8deOctubreyCentenario-EspLibreLarranaga_20190828_dji_pc_5cm\", \"AntelArena_20200804_dji_pc_5c\"]\n",
    "# coco_annotations = load_coco_annotations_from_mongodb(field_name=\"cvat\", images_names=images_list, clean_files=False)\n",
    "# save_coco_annotations(coco_annotations, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_image_width_height(image_id: str, width: int, height: int) -> bool:\n",
    "    \"\"\"Actualiza el ancho y alto de una imagen en la base de datos.\n",
    "\n",
    "    Args:\n",
    "        image_id (str): Identificador de la imagen a actualizar.\n",
    "        width (int): Nuevo ancho de la imagen.\n",
    "        height (int): Nuevo alto de la imagen.\n",
    "\n",
    "    Returns:\n",
    "        bool: True si la actualizaci√≥n fue exitosa, False en caso contrario.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        imagenes = DB.get_collection(\"imagenes\")\n",
    "        result = imagenes.update_one(\n",
    "            {\"id\": image_id},\n",
    "            {\n",
    "                \"$set\": {\n",
    "                    \"width\": width,\n",
    "                    \"height\": height,\n",
    "                }\n",
    "            },\n",
    "        )\n",
    "        if result.modified_count > 0:\n",
    "            LOGGER.debug(f\"Ancho y alto de la imagen {image_id} actualizados correctamente.\")\n",
    "            return True\n",
    "        else:\n",
    "            LOGGER.warning(f\"No se encontraron cambios para la imagen {image_id}.\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        LOGGER.error(f\"Error al actualizar el ancho y alto de la imagen {image_id}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_width_height_images():\n",
    "    \"\"\"Corrige el ancho y alto de las im√°genes en la base de datos.\n",
    "\n",
    "    Esta funci√≥n descarga las im√°genes desde MinIO, obtiene sus dimensiones (ancho y alto),\n",
    "    actualiza estos valores en la base de datos y elimina las im√°genes descargadas localmente.\n",
    "\n",
    "    Pasos realizados:\n",
    "    1. Configura el logger para registrar las actualizaciones.\n",
    "    2. Obtiene todas las im√°genes almacenadas en la base de datos.\n",
    "    3. Descarga cada imagen desde MinIO si est√° marcada como descargada.\n",
    "    4. Calcula las dimensiones de la imagen descargada.\n",
    "    5. Actualiza las dimensiones en la base de datos.\n",
    "    6. Elimina la imagen descargada localmente.\n",
    "\n",
    "    Raises:\n",
    "        OSError: Si ocurre un error al eliminar la imagen descargada localmente.\n",
    "    \"\"\"\n",
    "\n",
    "    set_log_to_file(f\"updates_{datetime.date.today()}.log\")\n",
    "    LOGGER.setLevel(logging.INFO)\n",
    "    LOGGER.info(\"Iniciando actualizaci√≥n de im√°genes y parches.\")\n",
    "    # Actualizar el width y height de las im√°genes en la base de datos\n",
    "    # 1 - Obtener todas las im√°genes de la base de datos\n",
    "    imagenes = DB.get_collection(\"imagenes\")\n",
    "\n",
    "    # 2 - Para cada imagen:\n",
    "    for image in imagenes.find():\n",
    "        image_id = image[\"id\"]\n",
    "        downloaded: bool = image[\"downloaded\"]\n",
    "        if not downloaded:\n",
    "            LOGGER.warning(f\"La imagen {image_id} no est√° descargada, se omitir√°.\")\n",
    "            continue\n",
    "        LOGGER.info(f\"Actualizando imagen {image_id}...\")\n",
    "        # 2.1 - Descargar la imagen desde MinIO\n",
    "\n",
    "        jpg_path = download_image_from_minio(image_id)\n",
    "        LOGGER.info(f\"Imagen {image_id} descargada correctamente.\")\n",
    "        # 2.2 - Obtener el ancho y alto de la imagen descargada\n",
    "        img = cv.imread(jpg_path)\n",
    "        height, width = img.shape[:2]\n",
    "        # 2.3 - Actualizar el ancho y alto de la imagen en la base de datos\n",
    "        fix_image_width_height(image_id, width, height)\n",
    "        LOGGER.info(f\"Ancho y alto de la imagen {image_id} actualizados correctamente.\")\n",
    "        # 2.4 - Eliminar la imagen descargada\n",
    "        try:\n",
    "            os.remove(jpg_path)\n",
    "            LOGGER.info(f\"Imagen {jpg_path} eliminada correctamente.\")\n",
    "        except OSError as e:\n",
    "            LOGGER.warning(f\"Error al eliminar la imagen {jpg_path}: {e}\")\n",
    "            continue\n",
    "    LOGGER.info(\"Actualizaci√≥n de im√°genes y parches finalizada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_dates_images():\n",
    "    set_log_to_file(f\"fix_dates_images_{datetime.date.today()}.log\")\n",
    "    LOGGER.setLevel(logging.INFO)\n",
    "    LOGGER.info(\"Iniciando actualizaci√≥n de fechas de im√°genes.\")\n",
    "    # Actualizar el width y height de las im√°genes en la base de datos\n",
    "    # 1 - Obtener todas las im√°genes de la base de datos\n",
    "    imagenes = DB.get_collection(\"imagenes\")\n",
    "    date_format = \"%d/%m/%Y\"\n",
    "\n",
    "    # 2 - Para cada imagen:\n",
    "    for image in imagenes.find():\n",
    "        # 2.1 - Obtener el t√≠tulo de la imagen\n",
    "        image_title = image[\"title\"]\n",
    "\n",
    "        # 2.2 - Extraer la fecha del t√≠tulo de la imagen\n",
    "        match = re.search(r\"\\d{2}/\\d{2}/\\d{4}\", image_title)\n",
    "        date_str = match.group(0) if match else None\n",
    "        if not date_str:\n",
    "            LOGGER.warning(f\"No se encontr√≥ una fecha v√°lida en el t√≠tulo de la imagen {image_title}.\")\n",
    "            continue\n",
    "\n",
    "        # 2.3 - Actualizar la fecha de captura en la base de datos\n",
    "        try:\n",
    "            date_captured = datetime.datetime.strptime(date_str, date_format)\n",
    "            imagenes.update_one(\n",
    "                {\"id\": image[\"id\"]},\n",
    "                {\n",
    "                    \"$set\": {\n",
    "                        \"date_captured\": date_captured,\n",
    "                    }\n",
    "                },\n",
    "            )\n",
    "            LOGGER.info(f\"Fecha de captura de la imagen {image_title} actualizada correctamente.\")\n",
    "        except Exception as e:\n",
    "            LOGGER.warning(f\"Error al actualizar la fecha de captura: {e}\")\n",
    "\n",
    "    LOGGER.info(\"Actualizaci√≥n de fechas de im√°genes finalizada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_patch_name():\n",
    "    \"\"\"Corrige el nombre de los parches en la base de datos.\n",
    "    Le saca el .jpg al final del nombre del parche y lo actualiza en la base de datos.\n",
    "    \"\"\"\n",
    "    set_log_to_file(f\"fix_patch_name_{datetime.date.today()}.log\")\n",
    "    LOGGER.setLevel(logging.INFO)\n",
    "    LOGGER.info(\"Iniciando actualizaci√≥n de nombres de parches.\")\n",
    "    # 1 - Obtener todas las im√°genes de la base de datos\n",
    "    imagenes = DB.get_collection(\"imagenes\")\n",
    "\n",
    "    # 2 - Para cada imagen:\n",
    "    for image in imagenes.find():\n",
    "        image_id = image[\"id\"]\n",
    "        # 2.1 - Obtener los parches de la imagen\n",
    "        try:\n",
    "            patches = image[\"patches\"]\n",
    "        except KeyError:\n",
    "            LOGGER.warning(f\"No se encontraron parches para la imagen {image_id}.\")\n",
    "            continue\n",
    "        # 2.2 - Para cada parche:\n",
    "        for patch in patches:\n",
    "            patch_name = patch[\"patch_name\"]\n",
    "            if patch_name.endswith(\".jpg\"):\n",
    "                new_patch_name = patch_name[:-4]\n",
    "                # 2.3 - Actualizar el nombre del parche en la base de datos\n",
    "                imagenes.update_one(\n",
    "                    {\"id\": image_id, \"patches.patch_name\": patch_name},\n",
    "                    {\"$set\": {\"patches.$.patch_name\": new_patch_name}},\n",
    "                )\n",
    "                LOGGER.info(f\"Nombre del parche {patch_name} actualizado a {new_patch_name}.\")\n",
    "            else:\n",
    "                LOGGER.warning(f\"El parche {patch_name} no tiene .jpg al final.\")\n",
    "    LOGGER.info(\"Actualizaci√≥n de nombres de parches finalizada.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
