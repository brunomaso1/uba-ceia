{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\"><b> ETIQUETADO - PROYECTO FINAL </b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\">üìù <em><small><font color='Gray'>Nota:</font></small></em></div>\n",
    "\n",
    "<div align=\"right\"> <em><small><font color='Gray'> La funcionalidad de visualizaci√≥n de jupyter notebooks en <a href=\"https://github.com/\" target=\"_blank\">github</a> es solamente un preview.</font></small></em> </div>\n",
    "\n",
    "<div align=\"right\"> <em><small><font color='Gray'> Para mejor visualizaci√≥n se sugiere utilizar el visualizador recomendado por la comunidad: <a href=\"https://nbviewer.org/\" target=\"_blank\">nbviewer</a></font></small></em> </div>\n",
    "\n",
    "<div align=\"right\"> <em><small><font color='Gray'> Puedes a acceder al siguiente enlace para ver este notebook en dicha p√°gina: <a href=\"https://nbviewer.org/ruta/de/archivo.ipynb\">Ruta archivo</a></font></small></em> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "/* Limitar la altura de las celdas de salida en html */\n",
    ".jp-OutputArea.jp-Cell-outputArea {\n",
    "    max-height: 500px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úã <em><font color='DodgerBlue'>Importaciones:</font></em> ‚úã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, logging, json, shutil, zipfile, copy, datetime\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../\"))  # Agregar el directorio padre al path\n",
    "\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from settings import Config\n",
    "from utils import MongoDB\n",
    "\n",
    "from cvat_sdk import make_client\n",
    "from cvat_sdk.core.proxies.types import Location\n",
    "\n",
    "from pymongo import UpdateOne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîß <em><font color='tomato'>Configuraciones:</font></em> üîß\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 16:26:17,869 - root - INFO - <module> - Configuraci√≥n cargada correctamente.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(\"../.env.dev\")\n",
    "\n",
    "# Crear instancia de Config\n",
    "CONFIG = Config(\"config.yaml\").config_data\n",
    "\n",
    "# Configuraci√≥n del logger\n",
    "logging.basicConfig(\n",
    "    format=CONFIG[\"logging\"][\"format\"],\n",
    "    level=logging.INFO if CONFIG[\"logging\"][\"level\"] == \"INFO\" else logging.DEBUG,\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Configuraci√≥n de MongoDB\n",
    "DB = MongoDB(CONFIG[\"mongodb\"][\"connection_string\"], CONFIG[\"mongodb\"][\"database\"]).db\n",
    "\n",
    "DOWNLOAD_TASK_FOLDER = os.path.join(CONFIG[\"download_folder\"], \"tasks\")\n",
    "DOWNLOAD_JOB_FOLDER = os.path.join(CONFIG[\"download_folder\"], \"jobs\")\n",
    "DOWNLOAD_TEMP_FOLDER = os.path.join(CONFIG[\"download_folder\"], \"temp\")\n",
    "DOWNLOAD_COCO_ANNOTATIONS_FOLDER = os.path.join(\n",
    "    CONFIG[\"download_folder\"], \"coco_annotations\"\n",
    ")\n",
    "\n",
    "\n",
    "logger.info(\"Configuraci√≥n cargada correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Colab -->\n",
    "<!-- <div align=\"center\"><img src=\"https://drive.google.com/uc?export=view&id=1QSNrTsz1hQbmZwpgwx0qpfpNtLW19Orm\" width=\"600\" alt=\"Figura 1: A data scientist is working on word generation using the Lord of the Rings lore. The image is dark and moody, with a focus on the scientist's computer screen. The screen displays a visualization the one ring, with a map of Middle Earth in the background. - Generada con DALL-E3\"></div> -->\n",
    "\n",
    "<!-- <div align=\"center\"><img src=\"./ceia-materia/resources/portada.jpeg\" width=\"600\" alt=\"Figura 1: A data scientist playing with convolutional neural networks. - Generada con Microsoft Image Creator\"></div>\n",
    "\n",
    "<div align=\"center\"><small><em>Figura 1: A data scientist playing with convolutional neural networks. - Generada con Microsoft Image Creator</em></small></div> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">‚ú®Datos del proyecto:‚ú®</div>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "| Subtitulo       | Etiquetado                                                                                                                             |\n",
    "| --------------- | -------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Descrpci√≥n**  | Herramientas y scripts para el etiquetado y guardado de los datos                                                                      |\n",
    "| **Integrantes** | Bruno Masoller (brunomaso1@gmail.com)                                                                                                  |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consinga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este proyecto es brindar herramientas y scripts para el etiquetado y guardado de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resoluci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilidades de Ultralytics:\n",
    "\n",
    "- [https://docs.ultralytics.com/es/usage/simple-utilities/](https://docs.ultralytics.com/es/usage/simple-utilities/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anotaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para las anotaciones, entre varios formatos estudiados, se eligi√≥ el formato de COCO.\n",
    "\n",
    "- [https://roboflow.com/formats/coco-json](https://roboflow.com/formats/coco-json)\n",
    "- [https://docs.voxel51.com/recipes/convert_datasets.html](https://docs.voxel51.com/recipes/convert_datasets.html)\n",
    "- [https://stackoverflow.com/questions/75927857/how-to-convert-coco-json-to-yolov8-segmentation-format](https://stackoverflow.com/questions/75927857/how-to-convert-coco-json-to-yolov8-segmentation-format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descargar anotaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_task_annotations_cvat(task_id: int, filename: str = None) -> str:\n",
    "    \"\"\"Descarga las anotaciones de una tarea de CVAT y las guarda en un archivo JSON.\n",
    "    Si el archivo ya existe, se elimina y se vuelve a descargar.\n",
    "\n",
    "    Se guarda el archivo JSON en la carpeta de descarga especificada en la configuraci√≥n.\n",
    "    Se eliminan los archivos temporales despu√©s de la descarga.\n",
    "\n",
    "    Args:\n",
    "        task_id (int): Identificador de la tarea de CVAT a descargar.\n",
    "        filename (str, optional): Nombre del archivo a descargar. Si no se proporciona, se utiliza el nombre por defecto.\n",
    "\n",
    "    Returns:\n",
    "        str: Ruta del archivo JSON descargado.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with make_client(\n",
    "            host=CONFIG[\"cvat\"][\"url\"],\n",
    "            credentials=(CONFIG[\"cvat\"][\"user\"], CONFIG[\"cvat\"][\"password\"]),\n",
    "        ) as client:\n",
    "            try:\n",
    "                task = client.tasks.retrieve(task_id).fetch()\n",
    "                os.makedirs(DOWNLOAD_TEMP_FOLDER, exist_ok=True)\n",
    "\n",
    "                filename = os.path.join(DOWNLOAD_TEMP_FOLDER, f\"cvat_task_{task_id}.zip\")\n",
    "\n",
    "                if os.path.exists(filename):\n",
    "                    os.remove(filename)\n",
    "                    logger.warning(\n",
    "                        f\"Archivo {filename} ya exist√≠a, se elimin√≥ para seguir el proceso (se lo descarga otra vez).\"\n",
    "                    )\n",
    "\n",
    "                task.export_dataset(\n",
    "                    format_name=CONFIG[\"cvat\"][\"export_format\"],\n",
    "                    filename=filename,\n",
    "                    include_images=False,\n",
    "                    location=Location.LOCAL,\n",
    "                )\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error al descargar la tarea {task_id}: {e}\")\n",
    "                return None\n",
    "            logger.debug(f\"Tarea {task_id} descargada correctamente.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error al conectar con CVAT: {e}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        with zipfile.ZipFile(filename, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(DOWNLOAD_TEMP_FOLDER)\n",
    "            logger.debug(f\"Archivo {filename} descomprimido correctamente.\")\n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(f\"Archivo no encontrado: {e}\")\n",
    "        return None\n",
    "    except zipfile.BadZipFile as e:\n",
    "        logger.error(f\"Error al descomprimir el archivo: {e}\")\n",
    "        return None\n",
    "\n",
    "    json_file = os.path.join(DOWNLOAD_TEMP_FOLDER, CONFIG[\"cvat\"][\"task_export_path\"])\n",
    "    os.makedirs(DOWNLOAD_TASK_FOLDER, exist_ok=True)\n",
    "    new_json_file_path = os.path.join(DOWNLOAD_TASK_FOLDER, f\"cvat_task_{task_id}.json\")\n",
    "\n",
    "    shutil.copy(json_file, new_json_file_path)\n",
    "    logger.debug(f\"Archivo JSON copiado a {new_json_file_path}.\")\n",
    "\n",
    "    try:\n",
    "        os.remove(filename)\n",
    "        logger.debug(f\"Archivo {filename} eliminado correctamente.\")\n",
    "\n",
    "        os.remove(json_file)\n",
    "        logger.debug(f\"Archivo {json_file} eliminado correctamente.\")\n",
    "    except OSError as e:\n",
    "        logger.warning(f\"Error al eliminar el archivos: {e}\")\n",
    "\n",
    "    return new_json_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_job_annotations_cvat(job_id: str, filename: str = None) -> str:\n",
    "    \"\"\"Descarga las anotaciones de un trabajo de CVAT y las guarda en un archivo JSON.\n",
    "    Si el archivo ya existe, se elimina y se vuelve a descargar.\n",
    "\n",
    "    Se guarda el archivo JSON en la carpeta de descarga especificada en la configuraci√≥n.\n",
    "    Se eliminan los archivos temporales despu√©s de la descarga.\n",
    "\n",
    "    Args:\n",
    "        job_id (str): Identificador del trabajo de CVAT a descargar.\n",
    "        filename (str, optional): Nombre del archivo a descargar. Si no se proporciona, se utiliza el nombre por defecto.\n",
    "\n",
    "    Returns:\n",
    "        str: Ruta del archivo JSON descargado.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        with make_client(\n",
    "            host=CONFIG[\"cvat\"][\"url\"],\n",
    "            credentials=(CONFIG[\"cvat\"][\"user\"], CONFIG[\"cvat\"][\"password\"]),\n",
    "        ) as client:\n",
    "            try:\n",
    "                job = client.jobs.retrieve(job_id).fetch()\n",
    "                os.makedirs(DOWNLOAD_TEMP_FOLDER, exist_ok=True)\n",
    "\n",
    "                filename = os.path.join(DOWNLOAD_TEMP_FOLDER, f\"cvat_job_{job_id}.zip\")\n",
    "\n",
    "                # Eliminamos el archivo si ya existe\n",
    "                if os.path.exists(filename):\n",
    "                    os.remove(filename)\n",
    "                    logger.warning(\n",
    "                        f\"Archivo {filename} ya exist√≠a, se elimin√≥ para seguir el proceso (se lo descarga otra vez).\"\n",
    "                    )\n",
    "\n",
    "                job.export_dataset(\n",
    "                    format_name=CONFIG[\"cvat\"][\"export_format\"],\n",
    "                    filename=filename,\n",
    "                    include_images=False,\n",
    "                    location=Location.LOCAL,\n",
    "                )\n",
    "            except Exception as e:\n",
    "                logger.error(\n",
    "                    f\"Error al descargar el job {job_id}: {e}\"\n",
    "                )\n",
    "                return None\n",
    "            logger.debug(f\"Job {job_id} descargada correctamente.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error al conectar con CVAT: {e}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        with zipfile.ZipFile(filename, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(DOWNLOAD_TEMP_FOLDER)\n",
    "            logger.debug(f\"Archivo {filename} descomprimido correctamente.\")\n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(f\"Archivo no encontrado: {e}\")\n",
    "        return None\n",
    "    except zipfile.BadZipFile as e:\n",
    "        logger.error(f\"Error al descomprimir el archivo: {e}\")\n",
    "        return None\n",
    "\n",
    "    json_file = os.path.join(DOWNLOAD_TEMP_FOLDER, CONFIG[\"cvat\"][\"job_export_path\"])\n",
    "    os.makedirs(DOWNLOAD_JOB_FOLDER, exist_ok=True)\n",
    "    new_json_file_path = os.path.join(DOWNLOAD_JOB_FOLDER, f\"cvat_job_{job_id}.json\")\n",
    "\n",
    "    shutil.copy(json_file, new_json_file_path)\n",
    "    logger.debug(f\"Archivo JSON copiado a {new_json_file_path}.\")\n",
    "\n",
    "    try:\n",
    "        os.remove(filename)\n",
    "        logger.debug(f\"Archivo {filename} eliminado correctamente.\")\n",
    "\n",
    "        os.remove(json_file)\n",
    "        logger.debug(f\"Archivo {json_file} eliminado correctamente.\")\n",
    "    except OSError as e:\n",
    "        logger.warning(f\"Error al eliminar el archivos: {e}\")\n",
    "\n",
    "    return new_json_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_annotations_google(url: str, filename: str) -> None:\n",
    "    \"\"\"Descarga las anotaciones de Google Maps.\n",
    "\n",
    "    Args:\n",
    "        url (str): URL del archivo en Google Maps.\n",
    "        filename (str): Nombre del archivo donde se guardar√°n las anotaciones.\n",
    "    \"\"\"\n",
    "    # Aqu√≠ ir√≠a la l√≥gica para descargar las anotaciones de Google Drive\n",
    "    # Por ejemplo, podr√≠as usar requests para hacer una solicitud a la API de Google Drive\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargar anotaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotations_from_file(file_path: str) -> dict[str, any]:\n",
    "    \"\"\"Carga las anotaciones desde un archivo JSON.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Ruta al archivo JSON\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: Anotaciones cargadas desde el archivo JSON.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        annotations = json.load(f)\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotations_from_cvat(\n",
    "    task_id: int = None, job_id: int = None\n",
    ") -> dict[str, any]:\n",
    "    \"\"\"Carga las anotaciones desde CVAT.\n",
    "\n",
    "    Este m√©todo permite descargar y cargar anotaciones desde CVAT, ya sea para una tarea\n",
    "    espec√≠fica o un trabajo espec√≠fico. Las anotaciones se descargan en formato JSON y \n",
    "    se cargan en un diccionario.\n",
    "\n",
    "    Args:\n",
    "        task_id (int, optional): Identificador de la tarea en CVAT. Defaults to None.\n",
    "        job_id (int, optional): Identificador del trabajo en CVAT. Defaults to None.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Si no se proporciona ni un task_id ni un job_id.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, any]: Diccionario con las anotaciones cargadas en formato COCO.\n",
    "    \"\"\"\n",
    "    file_path = None\n",
    "    try:\n",
    "        if task_id:\n",
    "            file_path = download_task_annotations_cvat(task_id)\n",
    "        elif job_id:\n",
    "            file_path = download_job_annotations_cvat(job_id)\n",
    "        else:\n",
    "            raise ValueError(\"Se debe proporcionar un task_id o un job_id.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error al descargar las anotaciones: {e}\")\n",
    "        return None\n",
    "\n",
    "    if file_path:\n",
    "        annotations = load_annotations_from_file(file_path)\n",
    "        logger.debug(f\"Anotaciones cargadas desde {file_path}.\")\n",
    "        return annotations\n",
    "    else:\n",
    "        logger.error(\"No se pudo cargar el archivo de anotaciones.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardar anotaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_coco_annotations(annotations: dict[str, any], field_name: str) -> bool:\n",
    "    \"\"\"Guarda las anotaciones en la base de datos MongoDB.\n",
    "\n",
    "    Este m√©todo procesa las anotaciones en formato COCO y las guarda en la base de datos MongoDB\n",
    "    asoci√°ndolas con las im√°genes y parches correspondientes. Si ya existen anotaciones para un \n",
    "    parche espec√≠fico, estas se eliminan antes de guardar las nuevas.\n",
    "\n",
    "    Args:\n",
    "        annotations (dict[str, any]): Diccionario con las anotaciones en formato COCO.\n",
    "        field_name (str): Nombre del campo donde se guardar√°n las anotaciones en la base de datos.\n",
    "\n",
    "    Returns:\n",
    "        bool: True si las anotaciones se guardaron correctamente, False en caso contrario.\n",
    "    \"\"\"\n",
    "    json_patches = annotations[\"images\"]\n",
    "    image_annotations = annotations[\"annotations\"]\n",
    "    categories = annotations[\"categories\"]\n",
    "\n",
    "    category_map = {cat[\"id\"]: cat[\"name\"] for cat in categories}\n",
    "\n",
    "    image_patch_pairs = []\n",
    "    upsert_operations = []\n",
    "\n",
    "    for json_patch in json_patches:\n",
    "        file_name = json_patch[\"file_name\"]\n",
    "        image_id = json_patch[\"id\"]\n",
    "        patch_name = file_name.split(\"/\")[-1]\n",
    "        image_name = file_name.split(\"/\")[-2]\n",
    "\n",
    "        image_patch_pairs.append((image_name, patch_name))\n",
    "\n",
    "        # Preparar los datos filtrados sin image_id\n",
    "        patch_annotations = [\n",
    "            {k: v for k, v in copy.deepcopy(ann).items() if k != \"image_id\"}\n",
    "            for ann in image_annotations\n",
    "            if ann[\"image_id\"] == image_id\n",
    "        ]\n",
    "\n",
    "        # Mapear las categor√≠as a los nombres correspondientes\n",
    "        patch_annotations = [\n",
    "            {**ann, \"category_name\": category_map[ann[\"category_id\"]]}\n",
    "            for ann in patch_annotations\n",
    "        ]\n",
    "\n",
    "        # Eliminar la clave category_id de las anotaciones\n",
    "        patch_annotations = [\n",
    "            {k: v for k, v in ann.items() if k != \"category_id\"}\n",
    "            for ann in patch_annotations\n",
    "        ]\n",
    "\n",
    "        # Crear operaci√≥n de actualizaci√≥n para MongoDB\n",
    "        upsert_operations.append(\n",
    "            UpdateOne(\n",
    "                {\"id\": image_name, \"patches.patch_name\": patch_name},\n",
    "                {\n",
    "                    \"$set\": {\n",
    "                        # Actualizar anotaciones en el patch espec√≠fico\n",
    "                        f\"patches.$.{field_name}_annotations\": patch_annotations,\n",
    "                        # Actualizar la fecha de modificaci√≥n a hoy\n",
    "                        f\"patches.$.last_modified\": datetime.datetime.now(),\n",
    "                    }\n",
    "                },\n",
    "                upsert=True,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Proceder con las operaciones en la base de datos\n",
    "    if image_patch_pairs:\n",
    "        imagenes = DB.get_collection(\"imagenes\")\n",
    "\n",
    "        # Primero, para cada par de imagen/parche, eliminar las anotaciones existentes\n",
    "        for image_name, patch_name in image_patch_pairs:\n",
    "            # Utilizar arrayFilters para actualizar s√≥lo el elemento espec√≠fico del array\n",
    "            imagenes.update_one(\n",
    "                {\"id\": image_name, \"patches.patch_name\": patch_name},\n",
    "                {\"$set\": {f\"patches.$.{field_name}_annotations\": []}},\n",
    "            )\n",
    "\n",
    "        logger.debug(\n",
    "            f\"Se eliminaron las anotaciones de {len(image_patch_pairs)} im√°genes/parches.\"\n",
    "        )\n",
    "\n",
    "        # Luego realizar las operaciones de actualizaci√≥n/inserci√≥n\n",
    "        if upsert_operations:\n",
    "            logger.debug(\n",
    "                f\"Se van a ejecutar {len(upsert_operations)} operaciones de actualizaci√≥n.\"\n",
    "            )\n",
    "            result = imagenes.bulk_write(upsert_operations, ordered=False)\n",
    "            logger.debug(f\"Documentos modificados: {result.modified_count}\")\n",
    "        return True\n",
    "    else:\n",
    "        logger.warning(\"No se encontraron pares de imagen/parche para actualizar.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtener anotaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_patch_annotations_as_coco(\n",
    "    patch_name: str, field_name: str, file_name: str = None\n",
    ") -> str:\n",
    "    \"\"\"Descarga las anotaciones de un parche en formato COCO y las guarda en un archivo JSON.\n",
    "\n",
    "    Este m√©todo permite obtener las anotaciones asociadas a un parche espec√≠fico desde la base de datos,\n",
    "    procesarlas en formato COCO y guardarlas en un archivo JSON.\n",
    "    El identificador de la imagen se establece en 1, y el nombre del archivo se genera a partir del nombre del parche.\n",
    "\n",
    "    Ejemplo de uso:\n",
    "        patch_name = \"8deOctubreyCentenario-EspLibreLarranaga_20190828_dji_pc_5cm_patch_0.jpg\"\n",
    "        field_name = \"cvat\"\n",
    "        download_patch_annotations_as_coco(patch_name, field_name)\n",
    "        # Esto generar√° un archivo JSON con las anotaciones en la carpeta de descarga especificada.\n",
    "\n",
    "    Args:\n",
    "        patch_name (str): Nombre del parche cuyas anotaciones se desean descargar.\n",
    "        field_name (str): Nombre del campo en la base de datos que contiene las anotaciones.\n",
    "        file_name (str, optional): Nombre del archivo donde se guardar√°n las anotaciones.\n",
    "                                   Si no se proporciona, se generar√° un nombre basado en el parche. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        str: Ruta del archivo JSON generado con las anotaciones en formato COCO.\n",
    "    \"\"\"\n",
    "    # Configuraci√≥n en general\n",
    "    info = CONFIG[\"coco_dataset\"][\"info\"]\n",
    "    licenses = CONFIG[\"coco_dataset\"][\"licenses\"]\n",
    "    categories = CONFIG[\"coco_dataset\"][\"categories\"]\n",
    "\n",
    "    category_map = {cat[\"name\"]: cat[\"id\"] for cat in categories}\n",
    "\n",
    "    db_images = DB.get_collection(\"imagenes\")\n",
    "    db_image = db_images.find_one(\n",
    "        {\"patches.patch_name\": patch_name},\n",
    "    )\n",
    "    if not db_image:\n",
    "        logger.error(\n",
    "            f\"No se encontr√≥ la imagen del parche {patch_name} en la base de datos.\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    # Filtramos el parche espec√≠fico\n",
    "    patch = next(\n",
    "        (p for p in db_image.get(\"patches\", []) if p[\"patch_name\"] == patch_name), None\n",
    "    )\n",
    "    if not patch:\n",
    "        logger.error(f\"No se encontr√≥ el parche {patch_name} en la base de datos.\")\n",
    "        return None\n",
    "\n",
    "    annotations = patch.get(f\"{field_name}_annotations\", [])\n",
    "    if not annotations:\n",
    "        logger.warning(f\"No se encontraron anotaciones para el parche {patch_name}.\")\n",
    "        return None\n",
    "\n",
    "    image = {\n",
    "        \"id\": 1,\n",
    "        \"width\": patch[\"width\"],\n",
    "        \"height\": patch[\"height\"],\n",
    "        \"file_name\": patch[\"patch_name\"],\n",
    "        \"date_captured\": patch[\"last_modified\"].strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    }\n",
    "\n",
    "    images = [image]\n",
    "\n",
    "    # Mapeamos las categor√≠as a los nombres correspondientes\n",
    "    annotations = [\n",
    "        {**ann, \"category_id\": category_map[ann[\"category_name\"]]}\n",
    "        for ann in annotations\n",
    "    ]\n",
    "\n",
    "    # Agregamos el campo image_id a las anotaciones\n",
    "    annotations = [{**ann, \"image_id\": image[\"id\"]} for ann in annotations]\n",
    "\n",
    "    # Eliminamos la clave category_name de las anotaciones\n",
    "    annotations = [\n",
    "        {k: v for k, v in ann.items() if k != \"category_name\"} for ann in annotations\n",
    "    ]\n",
    "\n",
    "    coco_annotations = {\n",
    "        \"info\": info,\n",
    "        \"licenses\": licenses,\n",
    "        \"categories\": categories,\n",
    "        \"images\": images,\n",
    "        \"annotations\": annotations,\n",
    "    }\n",
    "\n",
    "    output_file = (\n",
    "        file_name\n",
    "        if file_name\n",
    "        else os.path.join(\n",
    "            DOWNLOAD_COCO_ANNOTATIONS_FOLDER, f\"{field_name}_{patch_name}.json\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    os.makedirs(DOWNLOAD_COCO_ANNOTATIONS_FOLDER, exist_ok=True)\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(coco_annotations, f, indent=4)\n",
    "        logger.debug(f\"Archivo JSON guardado en {output_file}.\")\n",
    "\n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_patches_annotations_as_coco(\n",
    "    patch_names: list[str], field_name: str, file_name: str = None\n",
    ") -> str:\n",
    "    \"\"\"Descarga las anotaciones de m√∫ltiples parches en formato COCO y las guarda en un archivo JSON.\n",
    "\n",
    "    Este m√©todo permite obtener las anotaciones asociadas a m√∫ltiples parches desde la base de datos,\n",
    "    procesarlas en formato COCO y combinarlas en un √∫nico archivo JSON. El identificador de la imagen\n",
    "    se establece como un secuencial a partir de 0.\n",
    "\n",
    "    Ejemplo de uso:\n",
    "        patch_names = [\n",
    "            \"8deOctubreyCentenario-EspLibreLarranaga_20190828_dji_pc_5cm_patch_0.jpg\",\n",
    "            \"8deOctubreyCentenario-EspLibreLarranaga_20190828_dji_pc_5cm_patch_2.jpg\",\n",
    "        ]\n",
    "        field_name = \"cvat\"\n",
    "        download_patches_annotations_as_coco(patch_names, field_name)\n",
    "        # Esto generar√° un archivo JSON con las anotaciones combinadas en la carpeta de descarga especificada.\n",
    "\n",
    "    Args:\n",
    "        patch_names (list[str]): Lista de nombres de los parches cuyas anotaciones se desean descargar.\n",
    "        field_name (str): Nombre del campo en la base de datos que contiene las anotaciones.\n",
    "        file_name (str, optional): Nombre del archivo donde se guardar√°n las anotaciones combinadas.\n",
    "                                   Si no se proporciona, se generar√° un nombre por defecto. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        str: Ruta del archivo JSON generado con las anotaciones combinadas en formato COCO.\n",
    "    \"\"\"\n",
    "    coco_annotations = {\n",
    "        \"info\": CONFIG[\"coco_dataset\"][\"info\"],\n",
    "        \"licenses\": CONFIG[\"coco_dataset\"][\"licenses\"],\n",
    "        \"categories\": CONFIG[\"coco_dataset\"][\"categories\"],\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "    }\n",
    "\n",
    "    for image_id, patch_name in enumerate(patch_names):\n",
    "        output_file = download_patch_annotations_as_coco(\n",
    "            patch_name,\n",
    "            field_name,\n",
    "            os.path.join(DOWNLOAD_TEMP_FOLDER, f\"temp_{field_name}_{patch_name}.json\"),\n",
    "        )\n",
    "\n",
    "        if output_file:\n",
    "            with open(output_file, \"r\") as f:\n",
    "                patch_annotations = json.load(f)\n",
    "\n",
    "            patch_annotations[\"images\"][0][\"id\"] = image_id\n",
    "            patch_annotations[\"annotations\"] = [\n",
    "                {**ann, \"image_id\": image_id}\n",
    "                for ann in patch_annotations[\"annotations\"]\n",
    "            ]\n",
    "\n",
    "            # Agregar las im√°genes y anotaciones al diccionario principal\n",
    "            coco_annotations[\"images\"].extend(patch_annotations[\"images\"])\n",
    "            coco_annotations[\"annotations\"].extend(patch_annotations[\"annotations\"])\n",
    "\n",
    "            logger.debug(\n",
    "                f\"Anotaciones del parche {patch_name} agregadas correctamente.\"\n",
    "            )\n",
    "\n",
    "    # Guardar el archivo JSON final\n",
    "    output_file = (\n",
    "        file_name\n",
    "        if file_name\n",
    "        else os.path.join(\n",
    "            DOWNLOAD_COCO_ANNOTATIONS_FOLDER, f\"{field_name}_annotations.json\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Limpiar carpeta contenido de carpeta temporal\n",
    "    shutil.rmtree(DOWNLOAD_TEMP_FOLDER, ignore_errors=True)\n",
    "    os.makedirs(DOWNLOAD_TEMP_FOLDER, exist_ok=True)\n",
    "\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(coco_annotations, f, indent=4)\n",
    "        logger.debug(f\"Archivo JSON guardado en {output_file}.\")\n",
    "\n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image_annotations_as_coco(image_id: str, field_name: str) -> str:\n",
    "    # 1 - Obtener la imagen de la base de datos\n",
    "    imagenes = DB.get_collection(\"imagenes\")\n",
    "    image = imagenes.find_one({\"id\": image_id})\n",
    "\n",
    "    if not image:\n",
    "        logger.error(f\"No se encontr√≥ la imagen con id {image_id} en la base de datos.\")\n",
    "        return None\n",
    "\n",
    "    # 2 - Obtener los nombres de los parches asociados a la imagen\n",
    "    patches = image.get(\"patches\", [])\n",
    "    if not patches:\n",
    "        logger.warning(f\"No se encontraron parches asociados a la imagen {image_id}.\")\n",
    "        return None\n",
    "    patches_names = [patch[\"patch_name\"] for patch in patches]\n",
    "\n",
    "    # 3 - Ejecutar el m√©todo download_patches_annotations_as_coco\n",
    "    output_file = download_patches_annotations_as_coco(\n",
    "        patches_names,\n",
    "        field_name,\n",
    "        os.path.join(DOWNLOAD_TEMP_FOLDER, f\"temp_{field_name}_annotations.json\"),\n",
    "    )\n",
    "    if not output_file:\n",
    "        logger.error(f\"No se pudieron descargar las anotaciones de la imagen {image_id}.\")\n",
    "        return None\n",
    "    \n",
    "    # 4 - Crear el tipo de datos \"imagen\" con el id de la imagen y las dimensiones\n",
    "    image_data = {\n",
    "        \"id\": 1,\n",
    "        \"width\": image[\"width\"],\n",
    "        \"height\": image[\"height\"],\n",
    "        \"file_name\": image[\"file_name\"],\n",
    "        \"date_captured\": image[\"last_modified\"].strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    }\n",
    "    # 5 - Para cada annotaci√≥n, mapeamos los bboxes a coordenadas de la imagen\n",
    "    # 6 - Guardar el archivo JSON en la carpeta de descarga especificada en la configuraci√≥n\n",
    "    # 7 - Eliminar los archivos temporales despu√©s de la descarga\n",
    "    # 8 - Retornar la ruta del archivo JSON generado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtener im√°genes del repositorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image_from_minio(image_id: str) -> None:\n",
    "    \"\"\"Descarga la imagen desde MinIO.\n",
    "\n",
    "    Args:\n",
    "        image_id (str): id de la imagen\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mostrar anotaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_anotated_image(image_path: str, annotations: dict[str, any]) -> None:\n",
    "    \"\"\"Muestra la imagen con las anotaciones.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Ruta a la imagen\n",
    "        annotations (dict[str, any]): Anotaciones en formato COCO\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image_path: str) -> None:\n",
    "    \"\"\"Muestra la imagen.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Ruta a la imagen\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recortes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_palms_from_image(image_path: str, annotations: dict[str, any]) -> None:\n",
    "    \"\"\"Corta las palmas de la imagen seg√∫n las anotaciones.\n",
    "    Args:\n",
    "        image_path (str): Ruta a la imagen\n",
    "        annotations (dict[str, any]): Anotaciones en formato COCO\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_palms_to_minio(image_id: str, palms: list[str]) -> None:\n",
    "    \"\"\"Sube las palmas a MinIO.\n",
    "    Args:\n",
    "        image_id (str): id de la imagen\n",
    "        palms (list[str]): lista de rutas a las palmas\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
