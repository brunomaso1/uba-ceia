{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba de concepto de webscraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, re, json, logging, os, zipfile, sys, datetime, shutil\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from pymongo import MongoClient\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "from typing import Tuple, Optional\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración\n",
    "ENVIRONMENT = \"LOCAL\"  # PRODUCTION, LOCAL, SCALEWAY \n",
    "\n",
    "# Variables entorno\n",
    "# Cargar variables de entorno\n",
    "load_dotenv()\n",
    "\n",
    "# Variables de la base de datos\n",
    "MONGODB_INITDB_DATABASE = os.getenv(\"MONGODB_INITDB_DATABASE\")\n",
    "MONGODB_SERVER_HOST = os.getenv(\"MONGODB_SERVER_HOST\")\n",
    "MONGODB_SERVER_PORT = os.getenv(\"MONGODB_SERVER_PORT\")\n",
    "MONGODB_USER = os.getenv(\"MONGODB_USER\")\n",
    "MONGODB_PASSWORD = os.getenv(\"MONGODB_PASSWORD\")\n",
    "\n",
    "# Variables de S3\n",
    "S3_BUCKET = os.getenv(\"SCALEWAY_BUCKET\") if ENVIRONMENT == \"SCALEWAY\" else os.getenv(\"MINIO_BUCKET\")\n",
    "S3_ENDPOINT_URL = os.getenv(\"SCALEWAY_ENDPOINT_URL\") if ENVIRONMENT == \"SCALEWAY\" else os.getenv(\"MINIO_ENDPOINT_URL\")\n",
    "S3_ACCESS_KEY = os.getenv(\"SCALEWAY_ACCESS_KEY\") if ENVIRONMENT == \"SCALEWAY\" else os.getenv(\"MINIO_ACCESS_KEY\")\n",
    "S3_SECRET_KEY = os.getenv(\"SCALEWAY_SECRET_KEY\") if ENVIRONMENT == \"SCALEWAY\" else os.getenv(\"MINIO_SECRET_KEY\")\n",
    "S3_REGION = os.getenv(\"SCALEWAY_REGION\") if ENVIRONMENT == \"SCALEWAY\" else os.getenv(\"MINIO_REGION\")\n",
    "\n",
    "# Configura el logger\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(funcName)s - %(message)s\",\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Configuracion\n",
    "DOWNLOAD_PATH = \"./downloads\"\n",
    "MONGODB_CONECTION_STRING = f\"mongodb://{MONGODB_USER}:{MONGODB_PASSWORD}@{MONGODB_SERVER_HOST}:{MONGODB_SERVER_PORT}/{MONGODB_INITDB_DATABASE}\"\n",
    "PATCHES_PATH = os.path.join(DOWNLOAD_PATH, \"patches\")\n",
    "TILE_SIZE = (4096, 4096)\n",
    "OVER_LAP = 400\n",
    "PURGE_WHITE_IMAGES = True\n",
    "S3_BUCKET_IMAGES_PATH = \"imagenes\"\n",
    "S3_BUCKET_PATCHES_PATH = \"patches\"\n",
    "S3_BUCKET_METADATA_PATH = \"metadatos\"\n",
    "# OpenCV\n",
    "OPENCV_IO_MAX_IMAGE_PIXELS=17179869184 # Para imágenes grandes, ej: barrio3Ombues_20180801_dji_pc_3cm.jpg\n",
    "\n",
    "# Constantes\n",
    "URL_MAIN_PAGE = \"https://gis.montevideo.gub.uy/pmapper/map.phtml?&config=default&me=548000,6130000,596000,6162000\"\n",
    "URL_TOC = \"https://intgis.montevideo.gub.uy/pmapper/incphp/xajax/x_toc.php?\"\n",
    "URL_GENERATE_ZIP = \"https://intgis.montevideo.gub.uy/sit/php/common/datos/generar_zip2.php?nom_jpg=/inetpub/wwwroot/sit/mapserv/data/fotos_dron/{id}&tipo=jpg\"\n",
    "URL_DOWNLOAD_ZIP = \"https://intgis.montevideo.gub.uy/sit/tmp/{id}.zip\"\n",
    "URL_JS = \"https://intgis.montevideo.gub.uy/pmapper/config/default/custom.js\"\n",
    "\n",
    "HEADERS_COMMON = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\",\n",
    "}\n",
    "\n",
    "HEADERS_TOC = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\",\n",
    "    \"Referer\": URL_MAIN_PAGE,\n",
    "    \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "    \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "}\n",
    "\n",
    "BODY_TOC = {\"dummy\": \"dummy\"}\n",
    "\n",
    "# Importar OpenCV\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clase singleton para el cliente S3\n",
    "class S3Client:\n",
    "    __instance = None\n",
    "\n",
    "    @staticmethod\n",
    "    def get_instance():\n",
    "        if S3Client.__instance is None:\n",
    "            S3Client()\n",
    "        return S3Client.__instance\n",
    "\n",
    "    def __init__(self):\n",
    "        if S3Client.__instance is not None:\n",
    "            raise Exception(\"This class is a singleton!\")\n",
    "        else:\n",
    "            S3Client.__instance = self\n",
    "            self.client = boto3.client(\n",
    "                \"s3\",\n",
    "                endpoint_url=S3_ENDPOINT_URL,\n",
    "                aws_access_key_id=S3_ACCESS_KEY,\n",
    "                aws_secret_access_key=S3_SECRET_KEY,\n",
    "                region_name=S3_REGION,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clase singleton para MongoDB\n",
    "class MongoDB:\n",
    "    __instance = None\n",
    "    @staticmethod\n",
    "    def get_instance():\n",
    "        if MongoDB.__instance is None:\n",
    "            MongoDB()\n",
    "        return MongoDB.__instance\n",
    "    def __init__(self):\n",
    "        if MongoDB.__instance is not None:\n",
    "            raise Exception(\"Esta clase es un singleton!\")\n",
    "        else:\n",
    "            MongoDB.__instance = self\n",
    "            self.client = MongoClient(MONGODB_CONECTION_STRING)\n",
    "            self.db = self.client[MONGODB_INITDB_DATABASE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(url: str, headers: dict) -> str:\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        raise Exception(f\"Error al acceder a {url}. Razón: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_toc_html() -> str:\n",
    "    \"\"\"\n",
    "    Inicia una sesión, realiza una petición GET a la página principal y posteriormente\n",
    "    una petición POST para obtener el HTML que contiene la Table of Contents (TOC).\n",
    "\n",
    "    Returns:\n",
    "        str: El contenido HTML que representa la estructura TOC de la página.\n",
    "\n",
    "    Raises:\n",
    "        Exception: Si se produce un error HTTP (4xx o 5xx) al acceder a la URL de TOC,\n",
    "                   se lanza una excepción con un mensaje indicando la razón del fallo.\n",
    "    \"\"\"\n",
    "    \n",
    "    session = requests.Session()\n",
    "\n",
    "    try:\n",
    "        session.get(URL_MAIN_PAGE, headers=HEADERS_COMMON)\n",
    "        response = session.post(URL_TOC, headers=HEADERS_TOC, data=BODY_TOC)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        raise Exception(f\"Error al acceder a {URL_TOC}. Razón: {err}\")\n",
    "    finally:\n",
    "        session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pictures_list_html(html: str) -> str:\n",
    "    \"\"\"\n",
    "    A partir del HTML recibido, localiza el elemento `<li>` con id 'ligrp_grillaFotosDron'\n",
    "    y retorna el contenido HTML del `<ul>` padre que contiene las imágenes de drones.\n",
    "\n",
    "    Args:\n",
    "        html (str): Cadena que representa el contenido HTML de la página.\n",
    "\n",
    "    Returns:\n",
    "        str: El contenido HTML del elemento `<ul>` que contiene las imágenes de drones.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Si no se encuentra el `<li>` con el id especificado o si no existe\n",
    "                    un `<ul>` padre que lo contenga.\n",
    "    \"\"\"\n",
    "    \n",
    "    li_grilla_fotos_dron = \"ligrp_grillaFotosDron\"\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # 1) Buscamos el <li> deseado\n",
    "    li_drones_pictures = soup.find(\"li\", {\"id\": li_grilla_fotos_dron})\n",
    "    if li_drones_pictures is None:\n",
    "        raise ValueError(\"No se encontró el <li> con id='{li_grilla_fotos_dron}' en el HTML.\")\n",
    "    \n",
    "    # 2) Obtenemos el <ul> que lo contiene\n",
    "    ul_drones_pictures = li_drones_pictures.find_parent(\"ul\")\n",
    "    if ul_drones_pictures is None:\n",
    "        raise ValueError(\"No se encontró un elemento <ul> padre para el <li> con id='{li_grilla_fotos_dron}'.\")\n",
    "\n",
    "    # Devolvemos el HTML del <ul> que contiene las imágenes\n",
    "    return str(ul_drones_pictures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pics_dict(html: str) -> dict:\n",
    "    \"\"\"\n",
    "    Procesa el HTML de un `<ul>` para obtener información sobre cada elemento que\n",
    "    contiene imágenes de drones. Busca spans con IDs que coincidan con la expresión\n",
    "    regular `.*fotosDron.*` y extrae un identificador, así como el atributo `title`.\n",
    "\n",
    "    Args:\n",
    "        html (str): Contenido HTML que representa la lista de imágenes (un `<ul>`).\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de diccionarios, donde cada diccionario contiene:\n",
    "              - \"id\": Un índice secuencial que identifica el elemento.\n",
    "              - \"js_name\": Valor derivado del ID del span (remueve el prefijo 'spxg_').\n",
    "              - \"title\": El valor del atributo title del span interno con clase \"grp-title\".\n",
    "\n",
    "    Raises:\n",
    "        (No lanza excepciones explícitas propias, pero podría propagar excepciones de BeautifulSoup.)\n",
    "    \"\"\"\n",
    "    \n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    spans_fotos_dron = soup.find_all(\"span\", id=re.compile(r\".*fotosDron.*\"))\n",
    "\n",
    "    resultados = []\n",
    "\n",
    "    for idx, sp in enumerate(spans_fotos_dron, start=1):\n",
    "        # 1) Obtener el valor a partir del id del span\n",
    "        span_id = sp.get(\"id\", \"\")\n",
    "        value_attr = span_id.replace(\"spxg_\", \"\")\n",
    "        \n",
    "        # 2) El <span class=\"grp-title\" title=\"...\"> que está dentro\n",
    "        span_child_element = sp.find(\"span\")\n",
    "        if not span_child_element:\n",
    "            # Si no lo encuentra, pasa al siguiente\n",
    "            logger.warning(f\"No se encontró <span class='grp-title'> dentro del span con id='{span_id}'.\")\n",
    "            continue\n",
    "        title_attr = span_child_element.get(\"title\")\n",
    "        \n",
    "        # 3) Construir el objeto según el formato deseado\n",
    "        resultados.append({\n",
    "            \"id\": idx,\n",
    "            \"js_name\": value_attr,\n",
    "            \"title\": title_attr,\n",
    "        })\n",
    "\n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_picture(id: str) -> str|None:\n",
    "    \"\"\"\n",
    "    Dada una cadena `id`, realiza un get para generar un archivo ZIP en el servidor y luego\n",
    "    lo descarga si existe. El ZIP contiene las imágenes correspondientes al identificador.\n",
    "\n",
    "    Args:\n",
    "        id (str): Identificador que se usará para generar y descargar el ZIP.\n",
    "\n",
    "    Returns:\n",
    "        str | None: La ruta absoluta del archivo ZIP descargado. Retorna None si no se\n",
    "                    puede generar o descargar el ZIP.\n",
    "\n",
    "    Raises:\n",
    "        (Las excepciones de requests se manejan internamente, produciendo logs de error\n",
    "         o warning en caso de fallos. No se relanza la excepción.)\n",
    "    \"\"\"\n",
    "\n",
    "    # Ruta para generar el archivo ZIP en el servidor\n",
    "    url_generate_zip = URL_GENERATE_ZIP.format(id=id)\n",
    "\n",
    "    # Ruta para descargar el archivo ZIP\n",
    "    url_download_zip = URL_DOWNLOAD_ZIP.format(id=id)\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url_generate_zip, headers=HEADERS_COMMON)\n",
    "        response.raise_for_status()\n",
    "        logger.debug(f\"Archivo ZIP generado correctamente en el servidor. URL: {url_generate_zip}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.warning(f\"No se pudo generar el ZIP. URL: {url_generate_zip} - {e}\")\n",
    "    finally:\n",
    "        try:\n",
    "            response = requests.get(url_download_zip, headers=HEADERS_COMMON)\n",
    "            response.raise_for_status()\n",
    "            logger.debug(f\"Archivo ZIP descargado correctamente. URL: {url_download_zip}\")\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                file_name = f\"{id}.zip\"\n",
    "                os.makedirs(DOWNLOAD_PATH, exist_ok=True)\n",
    "\n",
    "                file_path = os.path.join(DOWNLOAD_PATH, file_name)\n",
    "                \n",
    "                with open(file_path, \"wb\") as f:\n",
    "                    f.write(response.content)\n",
    "                logger.debug(f\"Archivo '{file_name}' descargado correctamente en {file_path}\")\n",
    "                \n",
    "                return file_path\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logger.error(f\"No se pudo descargar el ZIP. URL: {url_download_zip} - {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_js_as_text() -> str:\n",
    "    return get_url(URL_JS, HEADERS_COMMON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_js_cases(js_code: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parsea el código JavaScript para encontrar las líneas que contengan casos y sus file_descarga.\n",
    "    \n",
    "    Args:\n",
    "        js_code (str): El contenido del archivo JavaScript.\n",
    "    Returns:\n",
    "        dict: Diccionario con los casos y sus rutas de archivo correspondientes.\n",
    "    \"\"\"\n",
    "    pattern = r\"\"\"case\\s+'([^']+)':\\s*\n",
    "                  (?:[^\\n]*\\n)?          # Captura opcional cualquier cosa hasta el fin de línea\n",
    "                  \\s*file_descarga\\s*=\\s*'([^']+)'\\s*;\"\"\"\n",
    "    \n",
    "    # re.VERBOSE permite escribir la regex más legible con comentarios\n",
    "    # re.MULTILINE permite que ^ y $ coincidan con principio y fin de línea\n",
    "    # re.DOTALL hace que . coincida también con saltos de línea\n",
    "    matches = re.findall(pattern, js_code, re.VERBOSE | re.MULTILINE | re.DOTALL)\n",
    "    \n",
    "    return {case_val: file_descarga for case_val, file_descarga in matches}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_download_file_id(js_text) -> str:\n",
    "    # Si tiene el prefijo \"fotos_dron/\", se lo removemos\n",
    "    return js_text.removeprefix(\"fotos_dron/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_file_download_id(resultados: list, mapping: dict) -> list:\n",
    "    \"\"\"\n",
    "    Agrega la clave 'file_download_id' a cada elemento de la lista `resultados`,\n",
    "    asociando su valor al correspondiente valor de `mapping` si existe.\n",
    "\n",
    "    Args:\n",
    "        resultados (list): Lista de diccionarios con al menos la clave \"js_name\".\n",
    "        mapping (dict): Diccionario con la relación \"js_name\" -> \"file_descarga\".\n",
    "\n",
    "    Returns:\n",
    "        list: La lista de diccionarios `resultados` modificada, donde cada elemento\n",
    "              incluye la clave 'file_download_id' extraída mediante la función\n",
    "              `obtener_id_file_descarga` si existe, o None en caso contrario.\n",
    "    \"\"\"\n",
    "    \n",
    "    for item in resultados:\n",
    "        value_attr = item[\"js_name\"]\n",
    "        # Si existe la key en el mapping, se la asignamos\n",
    "        if value_attr in mapping:\n",
    "            desc = mapping[value_attr]\n",
    "            item[\"file_download_id\"] = get_download_file_id(desc)\n",
    "            logger.debug(f\"Se asignó el valor '{item['file_download_id']}' a 'file_download_id' para '{value_attr}'.\")\n",
    "        else:\n",
    "            # Si no está, ponle None o algún valor por defecto\n",
    "            item[\"file_download_id\"] = None\n",
    "            logger.warning(f\"No se encontró un valor para '{value_attr}' en el mapping. Se asignó None.\")\n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_or_sync_downloaded(results: list) -> list:\n",
    "    \"\"\"\n",
    "    Agrega la clave 'downloaded' (estado) a cada elemento de la lista `resultados`, chequeando en la base de datos, indicando si el archivo ZIP asociado a ese elemento se está descargado o no.\n",
    "\n",
    "    Args:\n",
    "        resultados (list): Lista de diccionarios con al menos la clave \"id\".\n",
    "\n",
    "    Returns:\n",
    "        list: La lista de diccionarios `resultados` modificada, donde cada elemento\n",
    "              incluye la clave 'downloaded' con un valor booleano que indica si el archivo\n",
    "              ZIP se descargó o no.\n",
    "    \"\"\"\n",
    "    imagenes_db = MongoDB.get_instance().db.imagenes\n",
    "    for item in results:\n",
    "        # Busco en la base de datos si existe el item.\n",
    "        # Si existe el item, obtengo el estado.\n",
    "        # Sino, lo agrego a la base de datos y le pongo el estado en False.\n",
    "        item_db = imagenes_db.find_one({\"id\": item[\"file_download_id\"]})\n",
    "        if item_db:\n",
    "            item[\"downloaded\"] = item_db[\"downloaded\"]\n",
    "            logger.info(f\"El archivo ZIP asociado a '{item['file_download_id']}' está {'descargado' if item['downloaded'] else 'pendiente'}.\")\n",
    "        else:\n",
    "            logger.info(f\"El archivo ZIP asociado a '{item['file_download_id']}' no está en la base de datos. Se agregará.\")\n",
    "            imagenes_db.insert_one(\n",
    "                {\n",
    "                    \"id\": item[\"file_download_id\"],\n",
    "                    \"js_name\": item[\"js_name\"],\n",
    "                    \"title\": item[\"title\"],\n",
    "                    \"downloaded\": False\n",
    "                }\n",
    "            )\n",
    "            item[\"downloaded\"] = False        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_files(zip_path: str, id: str = None) -> Tuple[str | None, str | None]:\n",
    "    \"\"\"\n",
    "    Extrae los archivos JPG y JGW de un archivo ZIP descargado.\n",
    "\n",
    "    Args:\n",
    "        zip_path (str): Ruta absoluta del archivo ZIP descargado.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[str, str]: Tupla con las rutas absolutas de los archivos JPG y JGW extraídos.\n",
    "                         Si no se pudo extraer alguno de los archivos, se devuelve None.\n",
    "\n",
    "    Raises:\n",
    "        Exception: Si el ZIP no contiene exactamente dos archivos, se lanza una excepción.\n",
    "    \"\"\"\n",
    "    extract_dir = os.path.join(DOWNLOAD_PATH, \"extracted\")\n",
    "    os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(extract_dir)\n",
    "\n",
    "        # Encontrar los archivos JPG y JGW extraídos\n",
    "        jpg_file = None\n",
    "        jgw_file = None\n",
    "\n",
    "        # Obtengo los archivos extraídos\n",
    "        jpg_file = os.path.join(extract_dir, f\"{id}.jpg\")\n",
    "        jgw_file = os.path.join(extract_dir, f\"{id}.jgw\")\n",
    "\n",
    "        # Chequeo que existan los archivos\n",
    "        if not os.path.exists(jpg_file) or not os.path.exists(jgw_file):\n",
    "            logger.error(f\"No se encontraron los archivos JPG y JGW extraídos para {id}.\")\n",
    "            return None, None\n",
    "\n",
    "        logger.debug(f\"Archivo ZIP extraído de {id} correctamente. JPG: {jpg_file}, JGW: {jgw_file}\")\n",
    "        return jpg_file, jgw_file\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting files for {id}: {str(e)}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_img_to_s3(jpg_path: str, jgw_path: str, id: str) -> bool:\n",
    "    \"\"\"\n",
    "    Sube los archivos a Scaleway Object Storage usando boto3.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get S3 client\n",
    "        s3_client = S3Client.get_instance().client\n",
    "        \n",
    "        # Upload JPG file\n",
    "        with open(jpg_path, 'rb') as jpg_file:\n",
    "            s3_client.upload_fileobj(\n",
    "                jpg_file,\n",
    "                S3_BUCKET,\n",
    "                f\"{S3_BUCKET_IMAGES_PATH}/{id}.jpg\"\n",
    "            )\n",
    "            \n",
    "        # Upload JGW file\n",
    "        with open(jgw_path, 'rb') as jgw_file:\n",
    "            s3_client.upload_fileobj(\n",
    "                jgw_file,\n",
    "                S3_BUCKET,\n",
    "                f\"{S3_BUCKET_METADATA_PATH}/{id}.jgw\"\n",
    "            )\n",
    "\n",
    "        logger.debug(f\"Files uploaded to Scaleway: {id}\")            \n",
    "        return True\n",
    "        \n",
    "    except ClientError as e:\n",
    "        logger.error(f\"Error uploading to Scaleway: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jgw_data(jgw_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Lee un archivo JGW y devuelve un diccionario con los datos.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(jgw_path, \"r\") as jgw_file:\n",
    "            lines = jgw_file.readlines()\n",
    "            data = {\n",
    "                \"x_pixel_size\": float(lines[0].strip()),\n",
    "                \"y_rotation\": float(lines[1].strip()),\n",
    "                \"x_rotation\": float(lines[2].strip()),\n",
    "                \"y_pixel_size\": float(lines[3].strip()),\n",
    "                \"x_origin\": float(lines[4].strip()),\n",
    "                \"y_origin\": float(lines[5].strip())\n",
    "            }\n",
    "            logger.debug(f\"JGW file read successfully: {jgw_path}\")\n",
    "            return data\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error reading JGW file: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_mongodb(id: str, jgw_data: dict) -> bool:\n",
    "    \"\"\"\n",
    "    Agrega metadatos de la imagen a MongoDB y actualiza el estado de descarga a True.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        imagenes_db = MongoDB.get_instance().db.imagenes\n",
    "        result = imagenes_db.update_one(\n",
    "            {\"id\": id},\n",
    "            {\"$set\": {\n",
    "                \"downloaded\": True,\n",
    "                \"jgw_data\": jgw_data,\n",
    "                \"downloaded_date\": datetime.datetime.now()\n",
    "            }}\n",
    "        )\n",
    "        if result.modified_count > 0:\n",
    "            logger.debug(f\"MongoDB updated: {id}\")\n",
    "            return True\n",
    "        else:\n",
    "            logger.warning(f\"MongoDB not updated: {id}\")\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error updating MongoDB: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_directory(dir_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Elimina todo el contenido dentro del directorio especificado.\n",
    "    Si ocurre algún error, lanza la excepción correspondiente.\n",
    "    \n",
    "    Args:\n",
    "        dir_path (str): Ruta al directorio que se desea limpiar\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "            \n",
    "    Raises:\n",
    "        NotADirectoryError: Si la ruta existe pero no es un directorio\n",
    "        PermissionError: Si no hay permisos suficientes\n",
    "        OSError: Para otros errores del sistema operativo\n",
    "    \"\"\"\n",
    "    # Convertir a Path para mejor manejo\n",
    "    path = Path(dir_path)\n",
    "    \n",
    "    # Verificar si el directorio existe\n",
    "    if not path.exists():\n",
    "        logging.info(f\"El directorio {dir_path} no existe. No se requiere limpieza.\")\n",
    "        return\n",
    "        \n",
    "    # Verificar si es un directorio\n",
    "    if not path.is_dir():\n",
    "        raise NotADirectoryError(f\"La ruta {dir_path} no es un directorio\")\n",
    "        \n",
    "    # Verificar permisos\n",
    "    if not os.access(path, os.W_OK):\n",
    "        raise PermissionError(f\"Sin permisos de escritura en {dir_path}\")\n",
    "\n",
    "    # Eliminar contenido\n",
    "    for item in path.iterdir():\n",
    "        if item.is_file():\n",
    "            item.unlink()\n",
    "        elif item.is_dir():\n",
    "            shutil.rmtree(item)\n",
    "\n",
    "    logging.debug(f\"Directorio {dir_path} limpiado exitosamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_files(*file_paths: str) -> None:\n",
    "    \"\"\"\n",
    "    Removes temporary files after processing.\n",
    "    \"\"\"\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            if file_path and os.path.exists(file_path):\n",
    "                os.remove(file_path)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error cleaning up file {file_path}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_white_image(image, threshold_percent=50, white_threshold=250):\n",
    "    \"\"\"\n",
    "    Detecta imágenes blancas basándose en un porcentaje de píxeles blancos.\n",
    "    \n",
    "    Args:\n",
    "        image: Imagen en formato BGR (OpenCV)\n",
    "        threshold_percent: Porcentaje de blanco requerido\n",
    "        white_threshold: Valor mínimo para considerar un pixel como blanco (0-255)\n",
    "    \n",
    "    Returns:\n",
    "        bool: True si la imagen es considerada blanca\n",
    "        float: Porcentaje de blanco en la imagen\n",
    "    \"\"\"\n",
    "    # Convertir a HSV para mejor manejo del brillo\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Criterios para considerar un pixel como blanco\n",
    "    white_mask = cv2.inRange(hsv, \n",
    "                            np.array([0, 0, white_threshold]),  # Mínimo HSV\n",
    "                            np.array([180, 30, 255]))  # Máximo HSV\n",
    "\n",
    "    total_pixels = image.shape[0] * image.shape[1]\n",
    "    white_pixel_count = cv2.countNonZero(white_mask)\n",
    "    white_percentage = (white_pixel_count / total_pixels) * 100\n",
    "\n",
    "    return white_percentage > threshold_percent, white_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_image_with_overlap(id: str, jpg_path: str, tile_size: Tuple[int, int], overlap: int, purge_white_images: bool) -> Tuple[list, str]:\n",
    "    # Cargar la imagen\n",
    "    image = cv2.imread(jpg_path)\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Crear el directorio de salida si no existe\n",
    "    output_dir = os.path.join(PATCHES_PATH, id)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    metadata = []\n",
    "    patch_id = 0\n",
    "\n",
    "    # Recorrer la imagen en bloques con superposición\n",
    "    for y in range(0, height, tile_size[1] - overlap):\n",
    "        for x in range(0, width, tile_size[0] - overlap):\n",
    "            # Definir las coordenadas del recorte\n",
    "            x_end = min(x + tile_size[0], width)\n",
    "            y_end = min(y + tile_size[1], height)\n",
    "\n",
    "            # Recortar la región\n",
    "            tile = image[y:y_end, x:x_end]\n",
    "\n",
    "            tile_name = f\"{id}_patch_{patch_id}.jpg\"\n",
    "            \n",
    "            # Chequear si la mayoría de la imagen es blanca.\n",
    "            img_is_white = is_white_image(tile, threshold_percent=60, white_threshold=200)[0]\n",
    "\n",
    "            # Si la mayoría es balnca, y está activada la opción, no guardar la imagen.\n",
    "            if purge_white_images:\n",
    "                if not img_is_white:\n",
    "                    cv2.imwrite(os.path.join(output_dir, tile_name), tile)\n",
    "            else:\n",
    "                cv2.imwrite(os.path.join(output_dir, tile_name), tile)            \n",
    "\n",
    "            # Guardar los metadatos\n",
    "            metadata.append({\n",
    "                \"patch_id\": patch_id,\n",
    "                \"patch_name\": tile_name,\n",
    "                \"x_start\": x,\n",
    "                \"y_start\": y,\n",
    "                \"x_end\": x_end,\n",
    "                \"y_end\": y_end,\n",
    "                \"width\": x_end - x,\n",
    "                \"height\": y_end - y,\n",
    "                \"is_white\": img_is_white\n",
    "            })\n",
    "\n",
    "            patch_id += 1\n",
    "\n",
    "    return metadata, output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_patches_to_s3(id: str, patches_dir: str) -> bool:\n",
    "    \"\"\"\n",
    "    Sube los parches a Scaleway Object Storage usando boto3.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get S3 client\n",
    "        s3_client = S3Client.get_instance().client\n",
    "\n",
    "        # Listar los archivos en el directorio\n",
    "        for patch in os.listdir(patches_dir):\n",
    "            patch_path = os.path.join(patches_dir, patch)\n",
    "            with open(patch_path, \"rb\") as patch_file:\n",
    "                s3_client.upload_fileobj(\n",
    "                    patch_file, S3_BUCKET, f\"{S3_BUCKET_PATCHES_PATH}/{id}/{patch}\"\n",
    "                )\n",
    "\n",
    "        logger.debug(f\"Patches uploaded to Scaleway: {id}\")\n",
    "        return True\n",
    "\n",
    "    except ClientError as e:\n",
    "        logger.error(f\"Error uploading patches to Scaleway: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_mongodb_patches(id: str, patches: list) -> bool:\n",
    "    \"\"\"\n",
    "    Agrega metadatos de los parches a MongoDB.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        imagenes_db = MongoDB.get_instance().db.imagenes\n",
    "        result = imagenes_db.update_one(\n",
    "            {\"id\": id},\n",
    "            {\"$set\": {\n",
    "                \"patches\": patches,\n",
    "                \"patches_uploaded\": True\n",
    "            }}\n",
    "        )\n",
    "        if result.modified_count > 0:\n",
    "            logger.debug(f\"MongoDB updated with patches: {id}\")\n",
    "            return True\n",
    "        else:\n",
    "            logger.warning(f\"MongoDB not updated with patches: {id}\")\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error updating MongoDB with patches: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessingError(Exception):\n",
    "    \"\"\"Excepción personalizada para errores en el procesamiento de imágenes\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def process_and_upload_image(id: str, patches: bool = False, clean: bool = True) -> bool:\n",
    "    \"\"\"\n",
    "    Downloads, extracts and uploads drone images to Scaleway Object Storage.\n",
    "\n",
    "    Args:\n",
    "        download_id (str): The ID of the image to download\n",
    "\n",
    "    Returns:\n",
    "        bool: True if processing was successful, False otherwise\n",
    "\n",
    "    Raises:\n",
    "        ImageProcessingError: When any step in the process fails\n",
    "    \"\"\"\n",
    "    logger.info(f\"Starting processing for download_id: {id}\")\n",
    "\n",
    "    try:\n",
    "        # Download the ZIP file\n",
    "        zip_path = download_picture(id)\n",
    "        if not zip_path:\n",
    "            raise ImageProcessingError(f\"Failed to download ZIP for {id}\")\n",
    "        logger.info(f\"ZIP downloaded for {id}\")\n",
    "\n",
    "        # Extract files\n",
    "        jpg_path, jgw_path = extract_files(zip_path, id)\n",
    "        if not jpg_path or not jgw_path:\n",
    "            raise ImageProcessingError(f\"Failed to extract files from ZIP for {id}\")\n",
    "        logger.info(f\"Files extracted for {id}\")\n",
    "\n",
    "        # Upload to S3\n",
    "        upload_img_to_s3_result = upload_img_to_s3(jpg_path, jgw_path, id)\n",
    "        if not upload_img_to_s3_result:\n",
    "            raise ImageProcessingError(f\"Failed to upload files to S3 for {id}\")\n",
    "        logger.info(f\"Files uploaded to S3 for {id}\")\n",
    "\n",
    "        jgw_data = read_jgw_data(jgw_path)\n",
    "        if not jgw_data:\n",
    "            raise ImageProcessingError(f\"Failed to read JGW data for {id}\")\n",
    "        logger.info(f\"JGW data read for {id}\")\n",
    "\n",
    "        # Update MongoDB downloaded\n",
    "        update_mongodb_result = update_mongodb(id, jgw_data)\n",
    "        if not update_mongodb_result:\n",
    "            raise ImageProcessingError(f\"Failed to update MongoDB downloaded for {id}\")\n",
    "        logger.info(f\"MongoDB updated for {id}\")\n",
    "\n",
    "        if patches:\n",
    "            metadata, output_dir = split_image_with_overlap(\n",
    "                id,\n",
    "                jpg_path,\n",
    "                TILE_SIZE,\n",
    "                OVER_LAP,\n",
    "                PURGE_WHITE_IMAGES,\n",
    "            )\n",
    "            if not metadata:\n",
    "                raise ImageProcessingError(f\"Failed to split image for {id}\")\n",
    "            logger.info(f\"Image split for {id}\")\n",
    "\n",
    "            upload_patches_to_s3_result = upload_patches_to_s3(id, output_dir)\n",
    "            if not upload_patches_to_s3_result:\n",
    "                raise ImageProcessingError(f\"Failed to upload patches to S3 for {id}\")\n",
    "            logger.info(f\"Patches uploaded to S3 for {id}\")\n",
    "\n",
    "            update_mongodb_patches_result = update_mongodb_patches(id, metadata)\n",
    "            if not update_mongodb_patches_result:\n",
    "                raise ImageProcessingError(f\"Failed to update MongoDB patches for {id}\")\n",
    "            logger.info(f\"MongoDB updated with patches for {id}\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    except ImageProcessingError as e:\n",
    "        logger.error(str(e))\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error processing download_id {id}: {str(e)}\")\n",
    "        return False\n",
    "    finally:\n",
    "        try:\n",
    "            if clean:\n",
    "                clean_up_directory(DOWNLOAD_PATH)\n",
    "                logger.info(f\"Directory cleaned up for {id}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error cleaning up directory for {id}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_upload_patches(id: str, clean: bool = False) -> bool:\n",
    "    \"\"\"Descarga la imagen desde el bucket de S3, la divide en parches y los sube a S3. Finalmente, actualiza \n",
    "    la base de datos con los metadatos de los parches.\n",
    "\n",
    "    Args:\n",
    "        id (str): ID de la imagen a procesar.\n",
    "        clean (bool): Indica si se debe limpiar el directorio de descargas al finalizar el procesamiento.\n",
    "\n",
    "    Returns:\n",
    "        bool: True si el procesamiento fue exitoso, False en caso contrario.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Starting processing for download_id: {id}\")\n",
    "\n",
    "    try:\n",
    "        # Download the image from S3\n",
    "        jpg_path = os.path.join(PATCHES_PATH, f\"{id}.jpg\")\n",
    "\n",
    "        s3_client = S3Client.get_instance().client\n",
    "        s3_client.download_file(S3_BUCKET, f\"{S3_BUCKET_IMAGES_PATH}/{id}.jpg\", jpg_path)\n",
    "        logger.info(f\"Image downloaded from S3 for {id}\")\n",
    "\n",
    "        # Split image into patches\n",
    "        metadata, output_dir = split_image_with_overlap(\n",
    "            id,\n",
    "            jpg_path,\n",
    "            TILE_SIZE,\n",
    "            OVER_LAP,\n",
    "            PURGE_WHITE_IMAGES,\n",
    "        )\n",
    "        if not metadata:\n",
    "            raise ImageProcessingError(f\"Failed to split image for {id}\")\n",
    "        logger.info(f\"Image split for {id}\")\n",
    "\n",
    "        # Upload patches to S3\n",
    "        upload_patches_to_s3_result = upload_patches_to_s3(id, output_dir)\n",
    "        if not upload_patches_to_s3_result:\n",
    "            raise ImageProcessingError(f\"Failed to upload patches to S3 for {id}\")\n",
    "        logger.info(f\"Patches uploaded to S3 for {id}\")\n",
    "\n",
    "        # Update MongoDB with patches\n",
    "        update_mongodb_patches_result = update_mongodb_patches(id, metadata)\n",
    "        if not update_mongodb_patches_result:\n",
    "            raise ImageProcessingError(f\"Failed to update MongoDB patches for {id}\")\n",
    "        logger.info(f\"MongoDB updated with patches for {id}\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    except ImageProcessingError as e:\n",
    "        logger.error(str(e))\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error processing download_id {id}: {str(e)}\")\n",
    "        return False\n",
    "    finally:\n",
    "        try:\n",
    "            if clean:\n",
    "                clean_up_directory(DOWNLOAD_PATH)\n",
    "                logger.info(f\"Directory cleaned up for {id}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error cleaning up directory for {id}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_images() -> list:\n",
    "    \"\"\"\n",
    "    Returns all images from MongoDB.\n",
    "    \"\"\"\n",
    "    imagenes_db = MongoDB.get_instance().db.imagenes\n",
    "    return list(imagenes_db.find())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_log_to_file():\n",
    "    logger = logging.getLogger()\n",
    "    today = datetime.date.today()\n",
    "\n",
    "    log_file = f\"webscrapping_{today}.log\"\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(funcName)s - %(message)s')\n",
    "    file_handler = logging.FileHandler(log_file)\n",
    "    file_handler.setFormatter(formatter)\n",
    "\n",
    "    logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir todas las variables de entorno para debug\n",
    "# logger.info(\"Variables de entorno:\")\n",
    "# for key, value in os.environ.items():\n",
    "#     logger.info(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasos iniciales\n",
    "# Chequear conexión a MongoDB\n",
    "try:\n",
    "    MongoDB.get_instance()\n",
    "    # Listar las colecciones\n",
    "    collections = MongoDB.get_instance().db.list_collection_names()\n",
    "    logger.info(\"Connected to MongoDB\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error connecting to MongoDB: {str(e)}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Chequear conexión a S3\n",
    "try:\n",
    "    S3Client.get_instance()\n",
    "    # Listar los buckets\n",
    "    s3_client = S3Client.get_instance().client\n",
    "    response = s3_client.list_buckets()\n",
    "    logger.info(\"Connected to S3\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error connecting to S3: {str(e)}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# logger.setLevel(logging.INFO)\n",
    "# results = get_pics_dict(get_pictures_list_html(get_toc_html()))\n",
    "# mapping = parse_js_cases(get_js_as_text())\n",
    "\n",
    "# output = add_or_sync_downloaded(add_file_download_id(results, mapping))\n",
    "\n",
    "# Set log to file\n",
    "set_log_to_file()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Get all images from MongoDB\n",
    "images = get_all_images()\n",
    "\n",
    "# Slice the images to test\n",
    "images = images[0:40]\n",
    "\n",
    "# Process and upload images with tqdm\n",
    "logger.info(\"Starting processing and uploading images\")\n",
    "for image in tqdm(images):\n",
    "    if image[\"downloaded\"]:\n",
    "        logger.debug(f\"Skipping image {image['id']} as it is already downloaded\")\n",
    "    else:\n",
    "        logger.info(f\"Processing and uploading image {image['id']}\")\n",
    "        process_and_upload_image(image[\"id\"], patches=False, clean=False)\n",
    "logger.info(\"Finished processing and uploading images\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
