{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP3: Detector de SPAM - Solución\n",
    "\n",
    "![spam counter](./resources/spam.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción - Detectores de SPAM\n",
    "\n",
    "Uno de los problemas más comunes en la clasificación es la detección de correos electrónicos SPAM. Uno de los primeros \n",
    "modelos utilizados para abordar este problema fue el clasificador de Bayes ingenuo. La detección de SPAM es un problema \n",
    "persistente en el mundo digital, ya que los spammers continúan adaptando sus estrategias para eludir los filtros de \n",
    "correo no deseado. Además del clasificador de Bayes ingenuo, se han desarrollado y utilizado una variedad de técnicas \n",
    "más avanzadas en la detección de SPAM, que incluyen algoritmos de aprendizaje automático, redes neuronales y métodos \n",
    "basados en reglas.\n",
    "\n",
    "En este trabajo práctico, utilizaremos un conjunto de datos que consta de 4601 observaciones de correos electrónicos, \n",
    "de los cuales 2788 son correos legítimos y 1813 son correos SPAM. Dado que el contenido de los correos electrónicos es \n",
    "un tipo de dato no estructurado, es necesario procesarlo de alguna manera. Para este conjunto de datos, ya se ha \n",
    "aplicado un procesamiento típico en el Procesamiento del Lenguaje Natural (NLP), que consiste en contar la frecuencia \n",
    "de palabras observadas en los correos.\n",
    "\n",
    "El procesamiento de lenguaje natural (NLP) desempeña un papel fundamental en la detección de SPAM, ya que permite \n",
    "analizar el contenido de los correos electrónicos y extraer características relevantes para la clasificación. Además \n",
    "de contar la frecuencia de palabras, se pueden utilizar técnicas más sofisticadas, como la extracción de \n",
    "características semánticas y el análisis de sentimientos, para mejorar la precisión de los modelos de detección de SPAM.\n",
    "\n",
    "\n",
    "Con el fin de preservar la privacidad de los mensajes, la frecuencia de palabras se encuentra normalizada. El conjunto \n",
    "de datos está compuesto por 54 columnas de atributos que se denominan:\n",
    "\n",
    "- `word_freq_XXXX`: Donde `XXXX` es la palabra o símbolo. Los valores son enteros que van de 0 a 20k.\n",
    "\n",
    "Además, hay una columna adicional llamada `spam`, que es 1 si el correo es SPAM o 0 si no lo es."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tareas y preguntas a resolver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.naive_bayes import MultinomialNB   \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos obtenidos: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_edu</th>\n",
       "      <th>word_freq_table</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4522</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>409</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>340</td>\n",
       "      <td>170</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>1380</td>\n",
       "      <td>690</td>\n",
       "      <td>170</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2981</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1610</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>620</td>\n",
       "      <td>...</td>\n",
       "      <td>620</td>\n",
       "      <td>0</td>\n",
       "      <td>1860</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>170</td>\n",
       "      <td>1440</td>\n",
       "      <td>340</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>161</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "4522               0                  0              0             0   \n",
       "1603             340                170            170             0   \n",
       "2981               0                  0           1610             0   \n",
       "3945               0                  0              0             0   \n",
       "731              170                  0            170           170   \n",
       "\n",
       "      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "4522              0               0                 0                   0   \n",
       "1603           1380             690               170                 170   \n",
       "2981              0               0                 0                   0   \n",
       "3945              0               0                 0                   0   \n",
       "731            1440             340                50                  50   \n",
       "\n",
       "      word_freq_order  word_freq_mail  ...  word_freq_edu  word_freq_table  \\\n",
       "4522                0               0  ...           1130                0   \n",
       "1603                0             170  ...              0                0   \n",
       "2981                0               0  ...              0                0   \n",
       "3945                0             620  ...            620                0   \n",
       "731                50              50  ...              0                0   \n",
       "\n",
       "      word_freq_conference  char_freq_;  char_freq_(  char_freq_[  \\\n",
       "4522                     0            0          136            0   \n",
       "1603                     0            0          115            0   \n",
       "2981                     0            0          283            0   \n",
       "3945                  1860            0          122          122   \n",
       "731                      0           10           50            0   \n",
       "\n",
       "      char_freq_!  char_freq_$  char_freq_#  spam  \n",
       "4522            0            0          409     0  \n",
       "1603            0           86            0     1  \n",
       "2981            0            0            0     0  \n",
       "3945            0          214            0     0  \n",
       "731            10          161           30     1  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leemos el dataset\n",
    "df_spam = pd.read_csv(\"dataset/spambase.csv\")\n",
    "\n",
    "print(f'Datos obtenidos: ')\n",
    "df_spam.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4601 entries, 0 to 4600\n",
      "Data columns (total 55 columns):\n",
      " #   Column                Non-Null Count  Dtype\n",
      "---  ------                --------------  -----\n",
      " 0   word_freq_make        4601 non-null   int64\n",
      " 1   word_freq_address     4601 non-null   int64\n",
      " 2   word_freq_all         4601 non-null   int64\n",
      " 3   word_freq_3d          4601 non-null   int64\n",
      " 4   word_freq_our         4601 non-null   int64\n",
      " 5   word_freq_over        4601 non-null   int64\n",
      " 6   word_freq_remove      4601 non-null   int64\n",
      " 7   word_freq_internet    4601 non-null   int64\n",
      " 8   word_freq_order       4601 non-null   int64\n",
      " 9   word_freq_mail        4601 non-null   int64\n",
      " 10  word_freq_receive     4601 non-null   int64\n",
      " 11  word_freq_will        4601 non-null   int64\n",
      " 12  word_freq_people      4601 non-null   int64\n",
      " 13  word_freq_report      4601 non-null   int64\n",
      " 14  word_freq_addresses   4601 non-null   int64\n",
      " 15  word_freq_free        4601 non-null   int64\n",
      " 16  word_freq_business    4601 non-null   int64\n",
      " 17  word_freq_email       4601 non-null   int64\n",
      " 18  word_freq_you         4601 non-null   int64\n",
      " 19  word_freq_credit      4601 non-null   int64\n",
      " 20  word_freq_your        4601 non-null   int64\n",
      " 21  word_freq_font        4601 non-null   int64\n",
      " 22  word_freq_000         4601 non-null   int64\n",
      " 23  word_freq_money       4601 non-null   int64\n",
      " 24  word_freq_hp          4601 non-null   int64\n",
      " 25  word_freq_hpl         4601 non-null   int64\n",
      " 26  word_freq_george      4601 non-null   int64\n",
      " 27  word_freq_650         4601 non-null   int64\n",
      " 28  word_freq_lab         4601 non-null   int64\n",
      " 29  word_freq_labs        4601 non-null   int64\n",
      " 30  word_freq_telnet      4601 non-null   int64\n",
      " 31  word_freq_857         4601 non-null   int64\n",
      " 32  word_freq_data        4601 non-null   int64\n",
      " 33  word_freq_415         4601 non-null   int64\n",
      " 34  word_freq_85          4601 non-null   int64\n",
      " 35  word_freq_technology  4601 non-null   int64\n",
      " 36  word_freq_1999        4601 non-null   int64\n",
      " 37  word_freq_parts       4601 non-null   int64\n",
      " 38  word_freq_pm          4601 non-null   int64\n",
      " 39  word_freq_direct      4601 non-null   int64\n",
      " 40  word_freq_cs          4601 non-null   int64\n",
      " 41  word_freq_meeting     4601 non-null   int64\n",
      " 42  word_freq_original    4601 non-null   int64\n",
      " 43  word_freq_project     4601 non-null   int64\n",
      " 44  word_freq_re          4601 non-null   int64\n",
      " 45  word_freq_edu         4601 non-null   int64\n",
      " 46  word_freq_table       4601 non-null   int64\n",
      " 47  word_freq_conference  4601 non-null   int64\n",
      " 48  char_freq_;           4601 non-null   int64\n",
      " 49  char_freq_(           4601 non-null   int64\n",
      " 50  char_freq_[           4601 non-null   int64\n",
      " 51  char_freq_!           4601 non-null   int64\n",
      " 52  char_freq_$           4601 non-null   int64\n",
      " 53  char_freq_#           4601 non-null   int64\n",
      " 54  spam                  4601 non-null   int64\n",
      "dtypes: int64(55)\n",
      "memory usage: 1.9 MB\n"
     ]
    }
   ],
   "source": [
    "# Chequeamos los tipos de datos.\n",
    "df_spam.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_edu</th>\n",
       "      <th>word_freq_table</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>104.553358</td>\n",
       "      <td>213.014345</td>\n",
       "      <td>280.656379</td>\n",
       "      <td>65.424908</td>\n",
       "      <td>312.222995</td>\n",
       "      <td>95.900891</td>\n",
       "      <td>114.207564</td>\n",
       "      <td>105.294501</td>\n",
       "      <td>90.067377</td>\n",
       "      <td>239.413171</td>\n",
       "      <td>...</td>\n",
       "      <td>179.823734</td>\n",
       "      <td>5.444469</td>\n",
       "      <td>31.869159</td>\n",
       "      <td>38.574440</td>\n",
       "      <td>139.030428</td>\n",
       "      <td>16.975875</td>\n",
       "      <td>269.068898</td>\n",
       "      <td>75.810259</td>\n",
       "      <td>44.237992</td>\n",
       "      <td>0.394045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>305.357562</td>\n",
       "      <td>1290.574888</td>\n",
       "      <td>504.142884</td>\n",
       "      <td>1395.151370</td>\n",
       "      <td>672.511666</td>\n",
       "      <td>273.824083</td>\n",
       "      <td>391.440302</td>\n",
       "      <td>401.071452</td>\n",
       "      <td>278.615864</td>\n",
       "      <td>644.755399</td>\n",
       "      <td>...</td>\n",
       "      <td>911.118627</td>\n",
       "      <td>76.274271</td>\n",
       "      <td>285.734646</td>\n",
       "      <td>243.470469</td>\n",
       "      <td>270.355374</td>\n",
       "      <td>109.394164</td>\n",
       "      <td>815.669848</td>\n",
       "      <td>245.879440</td>\n",
       "      <td>429.341596</td>\n",
       "      <td>0.488698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>380.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>315.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4540.000000</td>\n",
       "      <td>14280.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>42810.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>5880.000000</td>\n",
       "      <td>7270.000000</td>\n",
       "      <td>11110.000000</td>\n",
       "      <td>5260.000000</td>\n",
       "      <td>18180.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>22050.000000</td>\n",
       "      <td>2170.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>4385.000000</td>\n",
       "      <td>9752.000000</td>\n",
       "      <td>4081.000000</td>\n",
       "      <td>32478.000000</td>\n",
       "      <td>6003.000000</td>\n",
       "      <td>19829.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "count     4601.000000        4601.000000    4601.000000   4601.000000   \n",
       "mean       104.553358         213.014345     280.656379     65.424908   \n",
       "std        305.357562        1290.574888     504.142884   1395.151370   \n",
       "min          0.000000           0.000000       0.000000      0.000000   \n",
       "25%          0.000000           0.000000       0.000000      0.000000   \n",
       "50%          0.000000           0.000000       0.000000      0.000000   \n",
       "75%          0.000000           0.000000     420.000000      0.000000   \n",
       "max       4540.000000       14280.000000    5100.000000  42810.000000   \n",
       "\n",
       "       word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "count    4601.000000     4601.000000       4601.000000         4601.000000   \n",
       "mean      312.222995       95.900891        114.207564          105.294501   \n",
       "std       672.511666      273.824083        391.440302          401.071452   \n",
       "min         0.000000        0.000000          0.000000            0.000000   \n",
       "25%         0.000000        0.000000          0.000000            0.000000   \n",
       "50%         0.000000        0.000000          0.000000            0.000000   \n",
       "75%       380.000000        0.000000          0.000000            0.000000   \n",
       "max     10000.000000     5880.000000       7270.000000        11110.000000   \n",
       "\n",
       "       word_freq_order  word_freq_mail  ...  word_freq_edu  word_freq_table  \\\n",
       "count      4601.000000     4601.000000  ...    4601.000000      4601.000000   \n",
       "mean         90.067377      239.413171  ...     179.823734         5.444469   \n",
       "std         278.615864      644.755399  ...     911.118627        76.274271   \n",
       "min           0.000000        0.000000  ...       0.000000         0.000000   \n",
       "25%           0.000000        0.000000  ...       0.000000         0.000000   \n",
       "50%           0.000000        0.000000  ...       0.000000         0.000000   \n",
       "75%           0.000000      160.000000  ...       0.000000         0.000000   \n",
       "max        5260.000000    18180.000000  ...   22050.000000      2170.000000   \n",
       "\n",
       "       word_freq_conference  char_freq_;  char_freq_(  char_freq_[  \\\n",
       "count           4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean              31.869159    38.574440   139.030428    16.975875   \n",
       "std              285.734646   243.470469   270.355374   109.394164   \n",
       "min                0.000000     0.000000     0.000000     0.000000   \n",
       "25%                0.000000     0.000000     0.000000     0.000000   \n",
       "50%                0.000000     0.000000    65.000000     0.000000   \n",
       "75%                0.000000     0.000000   188.000000     0.000000   \n",
       "max            10000.000000  4385.000000  9752.000000  4081.000000   \n",
       "\n",
       "        char_freq_!  char_freq_$   char_freq_#         spam  \n",
       "count   4601.000000  4601.000000   4601.000000  4601.000000  \n",
       "mean     269.068898    75.810259     44.237992     0.394045  \n",
       "std      815.669848   245.879440    429.341596     0.488698  \n",
       "min        0.000000     0.000000      0.000000     0.000000  \n",
       "25%        0.000000     0.000000      0.000000     0.000000  \n",
       "50%        0.000000     0.000000      0.000000     0.000000  \n",
       "75%      315.000000    52.000000      0.000000     1.000000  \n",
       "max    32478.000000  6003.000000  19829.000000     1.000000  \n",
       "\n",
       "[8 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chequeamos la estadística principal.\n",
    "df_spam.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notamos el primer problema, o punto a tener en cuenta, los valores máximos, en algunos casos son muy extremos. O sea, hay mails con 40.000 palabras repetidas de por ejemplo: 3d*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam\n",
       "0    2788\n",
       "1    1813\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vemos las cantidades frecuencia de la clase de salida.\n",
    "df_spam['spam'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores NaN:  0\n",
      "Valores nulos:  0\n"
     ]
    }
   ],
   "source": [
    "# Chequeamos valores nulos y NaN.\n",
    "nan_count = df_spam.isnull().sum().sum()\n",
    "null_count = df_spam.isnull().sum().sum()\n",
    "\n",
    "print('Valores NaN: ', nan_count)\n",
    "print('Valores nulos: ', null_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_freq_make          142\n",
       "word_freq_address       171\n",
       "word_freq_all           214\n",
       "word_freq_3d             43\n",
       "word_freq_our           255\n",
       "word_freq_over          141\n",
       "word_freq_remove        173\n",
       "word_freq_internet      170\n",
       "word_freq_order         144\n",
       "word_freq_mail          245\n",
       "word_freq_receive       113\n",
       "word_freq_will          316\n",
       "word_freq_people        158\n",
       "word_freq_report        133\n",
       "word_freq_addresses     118\n",
       "word_freq_free          253\n",
       "word_freq_business      197\n",
       "word_freq_email         229\n",
       "word_freq_you           575\n",
       "word_freq_credit        148\n",
       "word_freq_your          401\n",
       "word_freq_font           99\n",
       "word_freq_000           164\n",
       "word_freq_money         143\n",
       "word_freq_hp            395\n",
       "word_freq_hpl           281\n",
       "word_freq_george        240\n",
       "word_freq_650           200\n",
       "word_freq_lab           156\n",
       "word_freq_labs          179\n",
       "word_freq_telnet        128\n",
       "word_freq_857           106\n",
       "word_freq_data          184\n",
       "word_freq_415           110\n",
       "word_freq_85            177\n",
       "word_freq_technology    159\n",
       "word_freq_1999          188\n",
       "word_freq_parts          53\n",
       "word_freq_pm            163\n",
       "word_freq_direct        125\n",
       "word_freq_cs            108\n",
       "word_freq_meeting       186\n",
       "word_freq_original      136\n",
       "word_freq_project       160\n",
       "word_freq_re            230\n",
       "word_freq_edu           227\n",
       "word_freq_table          38\n",
       "word_freq_conference    106\n",
       "char_freq_;             313\n",
       "char_freq_(             641\n",
       "char_freq_[             225\n",
       "char_freq_!             962\n",
       "char_freq_$             504\n",
       "char_freq_#             316\n",
       "spam                      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chequeamos la unicicidad de los atributos.\n",
    "df_spam.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chequeamos valores duplicados.\n",
    "len(df_spam) - len(df_spam.drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nota: Cabe destacar que hay muchos valores duplicados. Estos valores hay que tenerlos en cuenta en los resultados de las predicciónes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1:\n",
    "\n",
    "> 1. ¿Cuáles son las 10 palabras más encontradas en correos con SPAM y en correos No SPAM? ¿Hay palabras en común? ¿Algunas llaman la atención?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correos SPAM (10 palabras más encontradas):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_you</th>\n",
       "      <th>word_freq_your</th>\n",
       "      <th>word_freq_will</th>\n",
       "      <th>word_freq_free</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>word_freq_email</th>\n",
       "      <th>word_freq_business</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4105599</td>\n",
       "      <td>2502597</td>\n",
       "      <td>997100</td>\n",
       "      <td>939790</td>\n",
       "      <td>931799</td>\n",
       "      <td>931352</td>\n",
       "      <td>732080</td>\n",
       "      <td>635470</td>\n",
       "      <td>578759</td>\n",
       "      <td>521250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_you  word_freq_your  word_freq_will  word_freq_free  \\\n",
       "1        4105599         2502597          997100          939790   \n",
       "\n",
       "   word_freq_our  char_freq_!  word_freq_all  word_freq_mail  word_freq_email  \\\n",
       "1         931799       931352         732080          635470           578759   \n",
       "\n",
       "   word_freq_business  \n",
       "1              521250  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agrupo por spam y me quedo solo con dicha fila.\n",
    "grouped_spam = df_spam.groupby(by=\"spam\", as_index=False).sum().iloc[1:2,:]\n",
    "\n",
    "# Obtengo los índices de las columnas más grandes.\n",
    "#   1 - Paso df a numpy.\n",
    "#   2 - Lo paso a una dimensión.\n",
    "#   3 - Lo ordeno (de forma inversa) y obtengo los 10 argumentos más grandes. \n",
    "lgt_items_index = np.argsort(grouped_spam.to_numpy().flatten())[-10:][::-1]\n",
    "\n",
    "print(f'Correos SPAM (10 palabras más encontradas):')\n",
    "# Simplemente filtro por ese vector de índices.\n",
    "grouped_spam.iloc[:,lgt_items_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correos NO SPAM (10 palabras más encontradas):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_you</th>\n",
       "      <th>word_freq_george</th>\n",
       "      <th>word_freq_hp</th>\n",
       "      <th>word_freq_will</th>\n",
       "      <th>word_freq_your</th>\n",
       "      <th>word_freq_hpl</th>\n",
       "      <th>word_freq_re</th>\n",
       "      <th>word_freq_edu</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_meeting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3541702</td>\n",
       "      <td>3527559</td>\n",
       "      <td>2496576</td>\n",
       "      <td>1495268</td>\n",
       "      <td>1223098</td>\n",
       "      <td>1204398</td>\n",
       "      <td>1159138</td>\n",
       "      <td>800669</td>\n",
       "      <td>681569</td>\n",
       "      <td>604460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_you  word_freq_george  word_freq_hp  word_freq_will  \\\n",
       "0        3541702           3527559       2496576         1495268   \n",
       "\n",
       "   word_freq_your  word_freq_hpl  word_freq_re  word_freq_edu  \\\n",
       "0         1223098        1204398       1159138         800669   \n",
       "\n",
       "   word_freq_address  word_freq_meeting  \n",
       "0             681569             604460  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agrupo por NO spam y me quedo solo con dicha fila.\n",
    "grouped_not_spam = df_spam.groupby(by=\"spam\", as_index=False).sum().iloc[0:1,:]\n",
    "\n",
    "# Obtengo los índices de las columnas más grandes.\n",
    "#   1 - Paso df a numpy.\n",
    "#   2 - Lo paso a una dimensión.\n",
    "#   3 - Lo ordeno (de forma inversa) y obtengo los 10 argumentos más grandes. \n",
    "lgt_items_index = np.argsort(grouped_not_spam.to_numpy().flatten())[-10:][::-1]\n",
    "\n",
    "print(f'Correos NO SPAM (10 palabras más encontradas):')\n",
    "# Simplemente filtro por ese vector de índices.\n",
    "grouped_not_spam.iloc[:,lgt_items_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2:\n",
    "\n",
    "> 2. Separe el conjunto de datos en un conjunto de entrenamiento y un conjunto de prueba (70% y 30% respectivamente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_spam.drop(columns=\"spam\")\n",
    "X = (df_spam.drop(columns=\"spam\") * 100).astype(int)\n",
    "y = df_spam[\"spam\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3:\n",
    "\n",
    "> 3. Utilizando un clasificador de Bayes ingenuo, entrene con el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalamos los datos.\n",
    "minmax_scaler = MinMaxScaler()\n",
    "X_train_scaled = minmax_scaler.fit_transform(X_train)\n",
    "X_test_scaled = minmax_scaler.transform(X_test)\n",
    "\n",
    "# Lo transformamos en DataFrames\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 4:\n",
    "\n",
    "> 4. Utilizando un clasificador de Regresión Logística, entrene con el conjunto de entrenamiento (en este caso, normalice los datos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalo los datos.\n",
    "standar_scaler = StandardScaler()\n",
    "X_train_scaled = standar_scaler.fit_transform(X_train)\n",
    "X_test_scaled = standar_scaler.transform(X_test)\n",
    "\n",
    "# Lo transformamos en DataFrames\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=10000, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=10000, random_state=0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=10000, random_state=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_balance = LogisticRegression(random_state = 0, class_weight=\"balanced\", max_iter=10000)\n",
    "classifier_balance.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 5:\n",
    "\n",
    "> 5. Calcule la matriz de confusión del conjunto de evaluación para ambos modelos. ¿Qué tipo de error comete más cada modelo? ¿Cuál de los dos tipos de error crees que es más importante para este problema?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 6:\n",
    "\n",
    "> 6. Calcule la precisión y la recuperación de ambos modelos. Para cada métrica, ¿cuál es el mejor modelo? ¿Cómo se relacionan estas métricas con los tipos de errores analizados en el punto anterior? Expanda su respuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 7:\n",
    "\n",
    "> 7. Obtenga la curva ROC y el AUC (Área Bajo la Curva ROC) de ambos modelos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
